{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of PET OSEM reconstruction with SIRF\n",
    "This demonstration shows how to use OSEM as implemented in SIRF. It also suggests some exercises for reconstruction with and without attenuation etc.\n",
    "\n",
    "The notebook is currently set-up to use prepared data with a single slice of an XCAT phantom, with a low resolution scanner, such that all results can be obtained easily on a laptop. Of course, the code will work exactly the same for any sized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Kris Thielemans and Evgueni Ovtchinnikov  \n",
    "First version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2018, 2021 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational Project in Synergistic Reconstruction for Biomedical Imaging (http://www.ccpsynerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is OSEM?\n",
    "The following is just a very brief explanation of the concepts behind OSEM.\n",
    "\n",
    "PET reconstruction is commonly based on the *Maximum Likelihood Estimation (MLE)* principle. The *likelihood* is the probability to observe some measured data given a (known) image. MLE attempts to find the image that maximises this likelihood. This needs to be done iteratively as the system of equations is very non-linear.\n",
    "\n",
    "A common iterative method uses *Expectation Maximisation*, which we will not explain here. The resulting algorithm is called *MLEM* (or sometimes *EMML*). However, it is rather slow. The most popular method to increase computation speed is to compute every image update based on only a subset of the data. Subsets are nearly always chosen in terms of the \"views\" (or azimuthal angles). The *Ordered Subsets Expectation Maximisation (OSEM)* cycles through the subsets. More on this in another notebook, but here we just show how to use the SIRF implementation of OSEM.\n",
    "\n",
    "OSEM is (still) the most common algorithm in use in clinical PET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure figures appears inline and animations works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setting-up of the data and working directory for the notebook.\n",
    "\n",
    "Please make sure that you have run the `download_data.sh` script first. See the [Introductory/introduction notebook](../Introductory/introduction.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import notebook_setup\n",
    "\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "#import scipy\n",
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import examples_data_path\n",
    "from sirf_exercises import exercises_data_path\n",
    "\n",
    "# define the directory with input files for this notebook\n",
    "data_path = os.path.join(examples_data_path('PET'), 'thorax_single_slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redirect STIR messages to some files\n",
    "STIR output can be a bit verbose. There are currently also some spurious warnings. To avoid distracting you, we redirect these messages to some files. You can check these if things go wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_red = pet.MessageRedirector('info.txt', 'warnings.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our usual handy function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_image(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    \"\"\"Customized version of subplot to plot 2D image\"\"\"\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will first create some simulated data from ground-truth images\n",
    "see previous notebooks for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read in images\n",
    "image = pet.ImageData(os.path.join(data_path, 'emission.hv'))\n",
    "attn_image = pet.ImageData(os.path.join(data_path, 'attenuation.hv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% display\n",
    "im_slice = image.dimensions()[0]//2\n",
    "plt.figure(figsize=(9, 4))\n",
    "plot_2d_image([1,2,1],image.as_array()[im_slice,:,:,], 'emission image')\n",
    "plot_2d_image([1,2,2],attn_image.as_array()[im_slice,:,:,], 'attenuation image')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% save max for future displays\n",
    "cmax = image.max()*.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create acquisition model\n",
    "acq_model = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "template = pet.AcquisitionData(os.path.join(data_path, 'template_sinogram.hs'))\n",
    "acq_model.set_up(template, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% simulate data using forward projection\n",
    "acquired_data=acq_model.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display bitmaps of a middle sinogram\n",
    "acquired_data.show(im_slice,title='Forward projection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction via a SIRF reconstruction class\n",
    "While you can write your own reconstruction algorithm by using `AcquisitionModel` etc (see  other notebooks), SIRF provides a few reconstruction clases. We show how to use the OSEM implementation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: create the objective function\n",
    "\n",
    "In PET, the iterative algorithms in SIRF rely on an objective function (i.e. the function to maximise).\n",
    "In PET, this is normally the Poisson log-likelihood. (We will see later about adding prior information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fun = pet.make_Poisson_loglikelihood(acquired_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could set acquisition model but the default (ray-tracing) is in this case ok. See below for more information. You could do this as follows.\n",
    "```\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "```\n",
    "\n",
    "We could also add a prior, but we will not do that here (although the rest of the exercise would still work). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: create OSMAPOSL reconstructor\n",
    "The `sirf.STIR.OSMAPOSLReconstructor` class implements the *Ordered Subsets Maximum A-Posteriori One Step Late algorithm*. That's quite a mouthful! We will get round to the \"OSL\" part, which is used to incorporate prior information. However, without a prior, this algorithm is identical to *Ordered Subsets Expectation Maximisation* (OSEM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = pet.OSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "# use 4 subset and 60 image updates. This is not too far from clinical practice.\n",
    "recon.set_num_subsets(4)\n",
    "num_subiters=60\n",
    "recon.set_num_subiterations(num_subiters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: use this reconstructor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an initial image. Passing this image automatically gives the dimensions of the output image.\n",
    "It is common practice to initialise OSEM with a uniform image. Here we use a value which is roughly of the correct scale, although this value doesn't matter too much (see discussion in the OSEM_DIY notebook).\n",
    "\n",
    "Then we need to set-up the reconstructor. That will do various checks and initial computations.\n",
    "\n",
    "And then finally we call the `reconstruct` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisation\n",
    "initial_image=image.get_uniform_copy(cmax / 4)\n",
    "recon.set_current_estimate(initial_image)\n",
    "# set up the reconstructor\n",
    "recon.set_up(initial_image)\n",
    "# do actual recon\n",
    "recon.process()\n",
    "reconstructed_image=recon.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "plot_2d_image([1,2,1],image.as_array()[im_slice,:,:,],'ground truth image',[0,cmax*1.2])\n",
    "plot_2d_image([1,2,2],reconstructed_image.as_array()[im_slice,:,:,],'reconstructed image',[0,cmax*1.2])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: write to file\n",
    "You can ask the `OSMAPOSLReconstructor` to write images to file every few sub-iterations, but this is by default disabled. We can however write the image to file from SIRF.\n",
    "\n",
    "For each \"engine\" its default file format is used, which for STIR is Interfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image.write('OSEM_result.hv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `write_par` member to specify a STIR parameter file to write in a different file format, but this is out of scope for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including a more realistic acquisition model\n",
    "The above steps were appropriate for an acquisition without attenuation etc. This is of course not appropriate for measured data.\n",
    "\n",
    "Let us use some things we've learned from the [image_creation_and_simulation notebook](image_creation_and_simulation.ipynb). First thing is to create a new acquisition model, then we need to use it to simulate new data, and finally to use it for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create attenuation\n",
    "acq_model_for_attn = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "asm_attn = pet.AcquisitionSensitivityModel(attn_image, acq_model_for_attn)\n",
    "asm_attn.set_up(template)\n",
    "attn_factors = asm_attn.forward(template.get_uniform_copy(1))\n",
    "asm_attn = pet.AcquisitionSensitivityModel(attn_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create acquisition model\n",
    "acq_model = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# we will increase the number of rays used for every Line-of-Response (LOR) as an example\n",
    "# (it is not required for the exercise of course)\n",
    "acq_model.set_num_tangential_LORs(5)\n",
    "acq_model.set_acquisition_sensitivity(asm_attn)\n",
    "# set-up\n",
    "acq_model.set_up(template,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "acquired_data = acq_model.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a background term of a reasonable scale\n",
    "background_term = acquired_data.get_uniform_copy(acquired_data.max()/10)\n",
    "acq_model.set_background_term(background_term)\n",
    "acquired_data = acq_model.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reconstructor\n",
    "obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "recon = pet.OSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "recon.set_num_subsets(4)\n",
    "recon.set_num_subiterations(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation and reconstruction\n",
    "recon.set_current_estimate(initial_image)\n",
    "recon.set_up(initial_image)\n",
    "recon.process()\n",
    "reconstructed_image=recon.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "plt.figure(figsize=(9, 4))\n",
    "plot_2d_image([1,2,1],image.as_array()[im_slice,:,:,],'ground truth image',[0,cmax*1.2])\n",
    "plot_2d_image([1,2,2],reconstructed_image.as_array()[im_slice,:,:,],'reconstructed image',[0,cmax*1.2])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: write a function to do an OSEM reconstruction\n",
    "The above lines still are quite verbose. So, your task is now to create a function that includes these steps, such that you can avoid writing all those lines all over again.\n",
    "\n",
    "For this, you need to know a bit about Python, but mostly you can copy-paste lines from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function that creates an acquisition model, given some input. Then we can write OSEM function that does the reconstruction.\n",
    "\n",
    "Below is a skeleton implementation. Look at the code above to fill in the details.\n",
    "\n",
    "To debug your code, it might be helpful at any messages that STIR writes. By default these are written to the terminal, but this is not helpful when running in a jupyter notebook. The line below will redirect all messages to files which you can open via the `File>Open` menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_red = pet.MessageRedirector('info.txt', 'warnings.txt', 'errors.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they will be located in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acq_model(attn_image, background_term):\n",
    "    '''create a PET acquisition model.\n",
    "    \n",
    "    Arguments:\n",
    "    attn_image: the mu-map\n",
    "    background_term: bakcground-term as an sirf.STIR.AcquisitionData\n",
    "    '''\n",
    "    # acq_model_for_attn = ...\n",
    "    # asm_model = ...\n",
    "    acq_model = pet.AcquisitionModelUsingRayTracingMatrix();\n",
    "    # acq_model.set_...\n",
    "    return acq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSEM(acq_data, acq_model, initial_image, num_subiterations, num_subsets=1):\n",
    "    '''run OSEM\n",
    "    \n",
    "    Arguments:\n",
    "    acq_data: the (measured) data\n",
    "    acq_model: the acquisition model\n",
    "    initial_image: used for initialisation (and sets voxel-sizes etc)\n",
    "    num_subiterations: number of sub-iterations (or image updates)\n",
    "    num_subsets: number of subsets (defaults to 1, i.e. MLEM)\n",
    "    '''\n",
    "    #obj_fun = ...\n",
    "    #obj_fun.set...\n",
    "    recon = pet.OSMAPOSLReconstructor()\n",
    "    #recon.set_objective_function(...)\n",
    "    #recon.set...\n",
    "    recon.set_current_estimate(initial_image)\n",
    "    recon.set_up(initial_image)\n",
    "    recon.process()\n",
    "    return recon.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test it with the above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_model = create_acq_model(attn_image, background_term)\n",
    "my_reconstructed_image = OSEM(acquired_data, acq_model, image.get_uniform_copy(cmax), 30, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: reconstruct with and without attenuation\n",
    "In some cases, it can be useful to reconstruct the emission data without taking attenuation (or even background terms) into account. One common example is to align the attenuation image to the emission image.\n",
    "\n",
    "It is easy to do such an *no--attenuation-correction (NAC)* recontruction in SIRF. You need to create an `AcquisitionModel` that does not include the attenuation factors, and use that for the reconstruction. (Of course, in a simulation context, you would still use the full model to do the simulation).\n",
    "\n",
    "Implement that here and reconstruct the data with and without attenuation to see visually what the difference is in the reconstructed images. If you have completed the previous exercise, you can use your own functions to do this.\n",
    "\n",
    "Hint: the easiest way would be to take the existing attenuation image, and use `get_uniform_copy(0)` to create an image where all $\\mu$-values are 0. Another (and more efficient) way would be to avoid creating the `AcquisitionSensitivityModel` at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises we have used attenuation images of the same size as the emission image. This is easier to code and for display etc, but it is not a requirement of SIRF.\n",
    "\n",
    "In addition, we have simulated and reconstructed the data with the same `AcquisitionModel` (and preserved image sizes). This is also convenient, but not a requirement (as you've seen in the NAC exercise). In fact, do not write your next paper using this \"inverse crime\". The problem is too "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
