{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating images using shapes and simple simulation for PET\n",
    "This exercise shows how to create images via geometric shapes. It then uses forward projection without\n",
    "and with attenuation. Exercises are given for extending the simulation to include noise and other parts of the PET model.\n",
    "\n",
    "Please note that the functionality for geometric shapes is currently specific to `sirf.STIR` as it relies on STIR classes.\n",
    "\n",
    "It is recommended you complete the [Introductory](../Introductory) notebooks first (or alternatively the [display_and_projection.ipynb](display_and_projection.ipynb)). There is some overlap with [acquisition_model_mr_pet_ct.ipynb](../Introductory/acquisition_model_mr_pet_ct.ipynb), but here we use some geometric shapes to create an image, add attenuation and go into more detail about PET specifics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Kris Thielemans and Evgueni Ovtchinnikov  \n",
    "First version: 8th of September 2016  \n",
    "Second version: 17th of May 2018  \n",
    "Third version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2018, 2021 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Synergistic Reconstruction for Biomedical Imaging\n",
    "(http://www.ccpsynerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib widget\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('PET', 'image_creation_and_simulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_setup\n",
    "\n",
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use the 'pet' prefix for all SIRF functions\n",
    "# This is done here to explicitly differentiate between SIRF pet functions and \n",
    "# anything else.\n",
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import show_2D_array, show_3D_array, examples_data_path\n",
    "from sirf_exercises import exercises_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory with input files\n",
    "data_path = os.path.join(examples_data_path('PET'), 'brain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read in image\n",
    "# We will use an image provided with the demo to have correct voxel-sizes etc\n",
    "image = pet.ImageData(os.path.join(data_path, 'emission.hv'))\n",
    "print(image.dimensions())\n",
    "print(image.voxel_sizes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create a shape\n",
    "shape = pet.EllipticCylinder()\n",
    "# define its size (in mm)\n",
    "shape.set_length(50)\n",
    "shape.set_radii((40, 30))\n",
    "# centre of shape in (x,y,z) coordinates where (0,0,0) is centre of first plane\n",
    "shape.set_origin((20, -30, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% add the shape to the image\n",
    "# first set the image values to 0\n",
    "image.fill(0)\n",
    "image.add_shape(shape, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% add same shape at different location and with different intensity\n",
    "shape.set_origin((40, -30, -60))\n",
    "image.add_shape(shape, scale=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show the phantom image as a sequence of transverse images\n",
    "show_3D_array(image.as_array());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple simulation\n",
    "Let's first do simple ray-tracing without attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create a SIRF acquisition model\n",
    "acq_model = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# Specify sinogram dimensions via the template\n",
    "template = pet.AcquisitionData(os.path.join(data_path, 'template_sinogram.hs'))\n",
    "# Now set-up our acquisition model with all information that it needs about the data and image.\n",
    "acq_model.set_up(template,image); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% forward project this image and display all sinograms\n",
    "acquired_data_no_attn = acq_model.forward(image)\n",
    "acquired_data_no_attn_array = acquired_data_no_attn.as_array()[0,:,:,:]\n",
    "show_3D_array(acquired_data_no_attn_array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Show every 8th view \n",
    "# Doing this here with a complicated one-liner...\n",
    "show_3D_array(\n",
    "    acquired_data_no_attn_array[:,0:acquired_data_no_attn_array.shape[1]:8,:].transpose(1,0,2),\n",
    "    show=False)\n",
    "# You could now of course try the animation of the previous demo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding attenuation\n",
    "Attenuation in PET follows the Lambert-Beer law:\n",
    "\n",
    "$$\\exp\\left\\{-\\int\\mu(x) dx\\right\\},$$\n",
    "\n",
    "with $\\mu(x)$ the linear attenuation coefficients (roughly proportional to density), \n",
    "and the line integral being performed between the 2 detectors.\n",
    "\n",
    "It is a specific \"feature\" of PET that the attenuation factor only depends on the line integral between the detectors, and not on the voxel location (this is different in SPECT). Therefore, it is common practice to model PET acquisitions by first doing ray-tracing, followed by multiplication by attenuation factors (which have the \"shape\" of acquired data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SIRF, we do this by including an `AcquisitionSensitivityModel` object in the `AcquisitionModel`. The rationale for the name is that attenuation reduces the sensitivity of the detector-pair. Let's do this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an attenuation image\n",
    "We will use the \"emission\" image as a template for sizes. This is easiest as the underlying STIR projector has a limitation that the voxel-size in the axial dimension has to be related to the ring spacing of the scanner. (Note that the voxel-sizes in the 2 other directions can be arbitrary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_image = image.get_uniform_copy(0)\n",
    "#%% create a shape for a uniform cylinder in the centre\n",
    "shape = pet.EllipticCylinder()\n",
    "shape.set_length(150)\n",
    "shape.set_radii((60, 60))\n",
    "shape.set_origin((0, 0, 40))\n",
    "# add it to the attenuation image with mu=-.096 cm^-1 (i.e. water)\n",
    "attn_image.add_shape(shape, scale=0.096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show the phantom image as a sequence of transverse images\n",
    "show_3D_array(attn_image.as_array());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Let's do a quick check that the values are fine\n",
    "attn_image.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the acquisition sensitivity model\n",
    "The variable will be called `asm_attn` to indicate that it's the \"acquisition sensitivity model for attenuation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the ray-tracer\n",
    "acq_model_for_attn = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# Now create the attenuation model\n",
    "asm_attn = pet.AcquisitionSensitivityModel(attn_image, acq_model_for_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to find the 'detection efficiencies' as sinograms\n",
    "asm_attn.set_up(template)\n",
    "attn_factors = asm_attn.forward(template.get_uniform_copy(1))\n",
    "# We will store these directly as an `AcquisitionSensitivityModel`, \n",
    "# such that we don't have to redo the line integrals\n",
    "asm_attn = pet.AcquisitionSensitivityModel(attn_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check a single sinogram (they are all the same for this simple case)\n",
    "show_2D_array('Attenuation factor sinogram', attn_factors.as_array()[0,5,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check a profile\n",
    "# we'll use TOF bin=0, sinogram=5, view=0\n",
    "plt.figure()\n",
    "plt.plot(attn_factors.as_array()[0,5,0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SIRF acquisition model incorporating attenuation\n",
    "We now add the attenuation to the full acquisition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with ray-tracing\n",
    "acq_model_with_attn = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# add the 'sensitivity'\n",
    "acq_model_with_attn.set_acquisition_sensitivity(asm_attn)\n",
    "# set-up\n",
    "acq_model_with_attn.set_up(template,image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new acquisition model\n",
    "Using `acq_model_with_attn` works exactly the same as without attenuation. Overhead in computation is also quite small as the attenuation factors were computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% forward project the original image, now including attenuation modelling, and display all sinograms\n",
    "acquired_data_with_attn = acq_model_with_attn.forward(image)\n",
    "acquired_data_with_attn_array = acquired_data_with_attn.as_array()[0,:,:,:]\n",
    "show_3D_array(acquired_data_with_attn_array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot some profiles\n",
    "slice = 40\n",
    "plt.figure()\n",
    "profile_no_attn = acquired_data_no_attn_array[5,slice,:]\n",
    "profile_with_attn = acquired_data_with_attn_array[5,slice,:]\n",
    "profile_attn_factors = attn_factors.as_array()[0,5,slice,:]\n",
    "\n",
    "plt.plot(profile_no_attn,label='no atten')\n",
    "plt.plot(profile_with_attn,label='with atten')\n",
    "plt.plot(profile_no_attn * profile_attn_factors,'bo',label='check')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further things to try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back project the data with and without attenuation and compare (easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As backprojection multiplies with the transpose matrix, does it \"undo\" attenuation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Poisson noise in the data (medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not so easy unfortunately. Adding noise is done in the [ML_reconstruction](ML_reconstruction.ipynb) exercise if you're stuck.\n",
    "\n",
    "One important thing to think about when using Poisson-distributed counts is that the mean value is important. This is because the variance is equal to the mean, resulting in lower relative noise for higher counts.\n",
    "\n",
    "You will therefore have to think about the scale of the image (or the scale of the acquisition data) before getting a Poisson noise sample.\n",
    "\n",
    "Hint: use `acquired_data.clone()` to create a copy, `numpy.random.poisson`, and `acquired_data.fill()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A question that might come to your mind is how you would model a scanner that is less sensitive. This can be done by including another `AcquisitionSensitivityModel` (i.e. another multiplicative factor). We will see this in action for the measured data. However, here you could already just multiply the attenuation data factors with a number before incorporating it into the acquisition sensitivity model, like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asm = pet.AcquisitionSensitivityModel(attn_factors* 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As SIRF (and STIR) reconstructed images are currently proportional to \"total counts per voxel\", you can use this strategy to incorporate duration and radioactive decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add an additive background to the model (easy)\n",
    "This is used to model \"accidental coincidences\" and \"scatter\". There are some choices to be made there as the question is if you have a term that should be added before or after attenuation. SIRF allows you to do both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an `AcquisitionData` object that is \"constant\" (i.e. has the same value everywhere) as model for your background (this is fairly realistic for accidential coincidences).\n",
    "\n",
    "Hint: read the help for `AcquisitionModel`. Create a simple background by using `AcquisitionData.get_uniform_copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pet.AcquisitionModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pet.AcquisitionData.get_uniform_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it modifies the forward projection (it should!), but what about the back-projection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen already with the backprojection with ray-tracing, but also when incorporating attenuation, backprojection in PET does **not** give you the inverse. In fact, even proportionality factors will be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical excursion\n",
    "In many modalities, backprojection is equivalent to the adjoint of the forward operation. However, the adjoint is only defined for linear models. If there is an additive background, the PET forward operator is no longer linear (but it is affine).\n",
    "\n",
    "The SIRF `backward` operation works for affine models as well. It multiplies data with the Jacobian of the forward model. This is useful for applying the chain rule. When expression images and data as (column) vectors, some mathematical manipulations will show that\n",
    "$$\\frac{\\partial}{\\partial x} f(A x + b) = A^t \\frac{\\partial}{\\partial y}f(y)|_{y=Ax+b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is no background term added after multiplication with $A^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many generic optimisation algorithms, including many implemented in CIL, work with linear operators and their adjoints. SIRF therefore allows you \"extract\" the linear operator (i.e. $A$ in the above formula) and the background term (i.e. $b$ in the above).\n",
    "\n",
    "Exercise: use SIRF methods to obtain the linear acquisition model and background, and write the \"full\" forward and backward operations in terms of those.\n",
    "\n",
    "Hint: read the help for the `AcquisitionModel`. In particular on the methods `get_constant_term` and `get_linear_acquisition_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pet.AcquisitionModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pet.AcquisitionModel.get_linear_acquisition_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for linear operators, `backward` is identical to `adjoint`. CIL currently only used the `adjoint` method.\n",
    "\n",
    "Final note: CIL uses the nomenclature `direct` for `forward`, hence these 2 methods are aliased in SIRF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use other settings for the acquisition data (medium)\n",
    "In the example above, we started from an existing \"template\" file. In SIRF, you can create a template based on a number of predefined scanners. An example is given in the [SIRF acquisition_data_from_scanner_info example](https://github.com/SyneRBI/SIRF/blob/v3.0.0/examples/Python/PET/acquisition_data_from_scanner_info.py).\n",
    "\n",
    "As stated before, SIRF has a limitation on the axial voxel size. Because of this you will have to create images with the correct axial spacing. The [Introductory/acquisition_model_mr_pet_ct notebook](../Introductory/acquisition_model_mr_pet_ct.ipynb) shows you how to construct an image appropriate for your scanner. An alternative is to use the SIRF resampling functions, please check the [Registration notebooks](../Reg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** (hard):\n",
    "\n",
    "Modify this exercise to use a Siemens mMR template based on the example quoted above.\n",
    "\n",
    "A difficulty currently is to understand the sirf.STIR coordinate system used by the geometrical shapes. Briefly, shapes are specified in a \"gantry\" system with coordinates `(a,v,h)` with `a` running in axial direction, `v` in vertical and `h` in horizontal. All are in mm, and `v=0,h=0` is on the scanner axis (but sadly, `a=0` is not in the centre. This is work in progress! (More detail is in the [STIR developers guide](http://stir.sourceforge.net/documentation/STIR-developers-overview.pdf).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might not know some PET nomenclature (such as \"span\" and \"view mashing\"). Briefly, higher \"span\" increases the amount of \"averaging\" used between ring differences, while \"view mashing\" allows you to add several views. They are used to reduce data size and hence speed up computation. \"full\" resolution sets `span=1, view_mashing=1`.\n",
    "\n",
    "This nomenclature is explained in the [STIR glossary](http://stir.sourceforge.net/documentation/STIR-glossary.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final note: modelling of other effects in SIRF?\n",
    "PET acquisition modelling should also include effects of different detection efficiencies, accidental coincidences and scatter.\n",
    "\n",
    "This is currently not feasible to do in the simple simulation context given here. For measured data, SIRF can read many scanners' efficiency (often called \"normalisation\") files, compute an estimate for the accidential coincidences as well as scatter. This is shown in other notebooks.\n",
    "\n",
    "In practice, many people therefore these terms from their measured data and then modify the image for simple simulations.\n",
    "\n",
    "SIRF *can* simulate scatter at lower resolution (or at high resolution but at high computational cost). You can have a look at the [SIRF scatter_simulation example](https://github.com/SyneRBI/SIRF/blob/v3.0.0/examples/Python/PET/scatter_simulation.py). (STIR can upsample the low resolution scatter estimate, but this functionality has not yet been exposed in SIRF 3.1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
