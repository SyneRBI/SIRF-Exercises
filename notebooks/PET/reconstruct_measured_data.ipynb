{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct phantom data\n",
    "This exercise shows how to handle data from the Siemens mMR. It shows how to get from listmode data to sinograms, get a randoms estimate, and reconstruct using normalisation, randoms and attenuation.\n",
    "(Scatter is not yet available from in SIRF).\n",
    "\n",
    "It is recommended you complete the first part of `ML_reconstruct.ipynb` exercise first.\n",
    "\n",
    "This exercise uses data from a phantom acquisition at UCL on a Siemens mMR. The phantom is the NEMA phantom (essentially a torso-shaped perspex box, with some spherical inserts). You will need to download that data. Please use the `SIRF-Exercises/scripts/download_PET_data.sh` script which will get the data, and make symbolic links in the location expected in this script. \n",
    "\n",
    "The script should work for other data of course, but you will need to adapt filenames.\n",
    "\n",
    "Note that we currently don't show how to extract the data from the console. Please\n",
    "[check our wiki for more information](https://github.com/CCPPETMR/SIRF/wiki/PET-raw-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Kris Thielemans and Evgueni Ovtchinnikov  \n",
    "First version: 8th of September 2016  \n",
    "Second Version: 17th of May 2018\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2018 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sirf.Utilities import show_2D_array, examples_data_path\n",
    "from sirf.STIR import *\n",
    "\n",
    "data_path = os.path.join('..', '..', 'data')\n",
    "nema_data_path = os.path.join(data_path, 'PET', 'mMR', 'NEMA_IQ')\n",
    "print('Finding files in %s' % nema_data_path)\n",
    "os.chdir(nema_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check content of current directory using an iPython \"magic\" command\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Siemens Normalisation into STIR format, some keys slightly differ\n",
    "!convertSiemensInterfileToSTIR.sh 20170809_NEMA_UCL.n.hdr norm.n.hdr\n",
    "!convertSiemensInterfileToSTIR.sh 20170809_NEMA_MUMAP_UCL.v.hdr umap.v.hdr\n",
    "\n",
    "# These files will sometimes have lines be terminated with CR instead of CRLF, fix this\n",
    "# This just means, if we see CR<character> and <character> isn't LF, replace it with CRLF<character>\n",
    "!sed -i \"s/\\r\\([^\\n]\\)/\\r\\n\\1/g\" norm.n.hdr\n",
    "!sed -i \"s/\\r\\([^\\n]\\)/\\r\\n\\1/g\" umap.v.hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% set filenames \n",
    "# input files\n",
    "list_file = '20170809_NEMA_60min_UCL.l.hdr'\n",
    "norm_file = 'norm.n.hdr'\n",
    "attn_file = 'umap.v.hdr'\n",
    "# output filename prefixes\n",
    "sino_file = 'sino'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redirect STIR messages to some files\n",
    "# you can check these if things go wrong\n",
    "msg_red = MessageRedirector('info.txt', 'warn.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sinograms from listmode data\n",
    "Modern PET scanners can store data in listmode format. This is essentially a long list of all events detected by the scanner. We are interested here in the *prompts* (the coincidence events) and the *delayed events* (which form an estimate of the *accidental coincidences* in the prompts.\n",
    "\n",
    "We show how to histogram the prompts into a sinogram etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First create a template for the sinogram\n",
    "This template is used to specify the sizes of the output sinogram.\n",
    "\n",
    "It is often the case in PET that we use sinograms with \"larger\" bins, i.e. combine data from several detector pairs into a single bin. This reduces size of the final sinogram, and decreases computation time. The terminology here is somewhat complicated, but *span* uses \"axial compression\" (higher span means smaller data size), *max_ring_diff* specifies the maximum ring difference to store, and *view_mash_factor* can be used to reduce the number of views (or azimutal angles).\n",
    "\n",
    "Siemens uses span=1, max_ring_diff=60 and view_mash_factor=1. Here we will use a smaller data size to reduce computation time for the exercise. Feel free to change these numbers (if you know what you are doing...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_acq_data = AcquisitionData('Siemens_mMR', span=11, max_ring_diff=15, view_mash_factor=2)\n",
    "template_acq_data.write('template.hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create listmode-to-sinograms converter object\n",
    "lm2sino = ListmodeToSinograms()\n",
    "\n",
    "# set input, output and template files\n",
    "lm2sino.set_input(list_file)\n",
    "lm2sino.set_output_prefix(sino_file)\n",
    "lm2sino.set_template('template.hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set timing interval (in secs) since start of acquisition\n",
    "# (the listmode file provided is for 1 hour).\n",
    "# you can vary this to see the effect on noise. Increasing it will mean somewhat longer\n",
    "# processing time in the following steps (but not in the reconstruction).\n",
    "lm2sino.set_time_interval(0, 600)  # 0 - 600 is the first 10 minutes\n",
    "# set up the converter\n",
    "lm2sino.set_up()\n",
    "# create the prompts sinogram\n",
    "lm2sino.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the content of the directory. there should be a `sino*.hs`, `'.s` pair.\n",
    "# The `.hs` file is an Interfile header pointing to the binary data.\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the prompts sinograms\n",
    "The 3D PET data returned by `as_array` are organised by 2D sinogram. The exact order of the sinograms\n",
    "is complicated for 3D PET, but they by *segment* (roughly: average ring difference). The first\n",
    "segment corresponds to \"segment 0\", i.e. detector pairs which are (roughly) in the same \n",
    "detector ring. For a scanner with `N` rings, there will be `2N-1` (2D) sinograms in segment 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get access to the sinograms\n",
    "acq_data = lm2sino.get_output()\n",
    "# copy the acquisition data into a Python array\n",
    "acq_array = acq_data.as_array()[0,:,:,:]  # first index is for ToF, which we don't have here\n",
    "# how many counts total in this segment?\n",
    "print('num prompts in this segments: %d' % acq_array.sum())\n",
    "# print the data sizes. \n",
    "print('acquisition data dimensions: %dx%dx%d' % acq_array.shape)\n",
    "# use a slice number for display that is appropriate for the NEMA phantom\n",
    "z = 71\n",
    "show_2D_array('Acquisition data', acq_array[z,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the *randoms* background\n",
    "Siemens stores *delayed coincidences*. These form a very noisy estimate of the\n",
    "background due to accidental coincidences in the data. However, that estimate is too noisy\n",
    "to be used in iterative image reconstruction.\n",
    "\n",
    "SIRF uses an algorithm from STIR that gives a much less noisy estimate. The help message \n",
    "gives some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lm2sino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the randoms estimate\n",
    "# This will take a while\n",
    "randoms = lm2sino.estimate_randoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the randoms-estimate\n",
    "A (2D) sinogram of the randoms has diagonal lines. This is related to the\n",
    "detector efficiencies, but we cannot get into that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms_array=randoms.as_array()[0,:,:,:]\n",
    "show_2D_array('randoms', randoms_array[z,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct the data\n",
    "We will reconstruct the data with increasingly accurate models for the acquisition as illustration.\n",
    "\n",
    "For simplicity, we will use OSEM and use only a few sub-iterations for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First just select an acquisition model that implements the geometric\n",
    "# forward projection by a ray tracing matrix multiplication\n",
    "acq_model = AcquisitionModelUsingRayTracingMatrix()\n",
    "acq_model.set_num_tangential_LORs(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function to be maximized as\n",
    "# Poisson logarithmic likelihood (with linear model for mean)\n",
    "obj_fun = make_Poisson_loglikelihood(acq_data)\n",
    "obj_fun.set_acquisition_model(acq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the reconstruction object\n",
    "recon = OSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "\n",
    "num_subsets = 7\n",
    "# Feel free to increase these\n",
    "num_subiterations = 4\n",
    "recon.set_num_subsets(num_subsets)\n",
    "recon.set_num_subiterations(num_subiterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial image estimate of dimensions and voxel sizes\n",
    "# compatible with the scanner geometry (included in the AcquisitionData\n",
    "# object acq_data) and initialize each voxel to 1.0\n",
    "nxny = (127, 127)\n",
    "initial_image = acq_data.create_uniform_image(1.0, nxny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = initial_image\n",
    "recon.set_up(image)\n",
    "# set the initial image estimate\n",
    "recon.set_current_estimate(image)\n",
    "# reconstruct\n",
    "recon.process()\n",
    "# show reconstructed image\n",
    "image_array = recon.get_current_estimate().as_array()\n",
    "show_2D_array('Reconstructed image', image_array[z,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add detector sensitivity modelling\n",
    "Each crystal pair will have different detection efficiency. We need to take that into account\n",
    "in our acquisition model. The scanner provides a *normalisation file* to do this (the terminology\n",
    "originates from the days that we were \"normalising\" by  dividing by the detected counts \n",
    "by the sensitivities.)\n",
    "\n",
    "In SIRF, you can incorporate this effect in the acquisition model by using an `AcquisitionSensitivityModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create it from the supplied file\n",
    "asm_norm = AcquisitionSensitivityModel(norm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add it to the acquisition model\n",
    "acq_model.set_acquisition_sensitivity(asm_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the objective function\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "recon.set_objective_function(obj_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "image = initial_image\n",
    "recon.set_up(image)\n",
    "recon.set_current_estimate(image)\n",
    "recon.process()\n",
    "# show reconstructed image\n",
    "image_array = recon.get_current_estimate().as_array()\n",
    "show_2D_array('Reconstructed image', image_array[z,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attenuation modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read attenuation image\n",
    "attn_image = ImageData(attn_file)\n",
    "z = 71\n",
    "attn_image.show(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_acq_model = AcquisitionModelUsingRayTracingMatrix()\n",
    "asm_attn = AcquisitionSensitivityModel(attn_image, attn_acq_model)\n",
    "# converting attenuation into attenuation factors (see previous exercise)\n",
    "asm_attn.set_up(acq_data)\n",
    "attn_factors = AcquisitionData(acq_data)\n",
    "attn_factors.fill(1.0)\n",
    "print('applying attenuation (please wait, may take a while)...')\n",
    "asm_attn.unnormalise(attn_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these in the final attenuation model\n",
    "asm_attn = AcquisitionSensitivityModel(attn_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two acquisition_sensitivity_models: for detection sensitivity and for\n",
    "count loss due to attenuation. We combine them by \"chaning\" them together (which will\n",
    "model the multiplication of both sensitivities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain attenuation and normalisation\n",
    "asm = AcquisitionSensitivityModel(asm_norm, asm_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the acquisition model etc\n",
    "acq_model.set_acquisition_sensitivity(asm)\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "recon.set_objective_function(obj_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "image = initial_image\n",
    "recon.set_up(image)\n",
    "recon.set_current_estimate(image)\n",
    "recon.process()\n",
    "# show reconstructed image\n",
    "image_array = recon.get_current_estimate().as_array()\n",
    "show_2D_array('Reconstructed image', image_array[z,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a background term for modelling the randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_model.set_background_term(randoms)\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "recon.set_objective_function(obj_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = initial_image\n",
    "recon.set_up(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon.set_current_estimate(image)\n",
    "recon.process()\n",
    "# show reconstructed image\n",
    "image_array = recon.get_current_estimate().as_array()\n",
    "show_2D_array('Reconstructed image', image_array[z,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
