{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of basic PET capabilities with SIRF: IO and projections\n",
    "This demonstration shows how to read images and data, display them. It then\n",
    "illustrates how to use an AcquisitionModel to forward and backproject.\n",
    "\n",
    "This notebook is largely superseded by the [Introductory/ notebooks](../Introductory/), which illustrate the same concepts with PET, MR and x-ray CT, but kept here as there are a few differences:\n",
    "- It uses similar images but smaller for speed.\n",
    "- It gives a little bit more information on dimensions of `AcquisitionData`.\n",
    "- For display, it uses the SIRF `show` method and also tells you how to run an animation in Python.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "You could export it as a Python file and run it one go, but that might\n",
    "make little sense as the figures are not labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kris Thielemans  \n",
    "First version: 8th of September 2016  \n",
    "Second version: 17th of May 2018  \n",
    "Third version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2018, 2021 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Synergistic Reconstruction for Biomedical Imaging\n",
    "(http://www.ccpsynerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure figures appear inline and animations work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above failed, or you experience problems plotting, you should restart the Python kernel and use the following line instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_setup\n",
    "\n",
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the 'pet' prefix for all STIR-based SIRF functions\n",
    "This is done here to explicitly differentiate between SIRF pet functions and anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import examples_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redirect STIR messages to some files\n",
    "STIR output can be a bit verbose. There are currently also some spurious warnings. To avoid distracting you, we redirect these messages to some files. You can check these if things go wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_red = pet.MessageRedirector('info.txt', 'warnings.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data and working directory for the notebook.\n",
    "\n",
    "Please make sure that you have run the `download_data.sh` script first. See the [Introductory/introduction notebook](../Introductory/introduction.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sirf_exercises import exercises_data_path\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('PET', 'image_creation_and_simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to a working folder and change directory to where these files are\n",
    "We do this to avoid cluttering your SIRF files. This way, you can delete \n",
    "`working_folder` and start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find directory with input files\n",
    "org_data_dir=os.path.join(examples_data_path('PET'),'brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing files just to be sure\n",
    "shutil.rmtree('./brain',True)\n",
    "# copy the whole folder\n",
    "shutil.copytree(org_data_dir,'./brain')\n",
    "# and go there\n",
    "os.chdir('./brain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. finally done with initial set-up..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image manipulations\n",
    "Images (like most other things in SIRF) are represented as *objects*, in this case of type `ImageData`.\n",
    "In practice, this means that you can only manipulate its data via *methods*.\n",
    "\n",
    "Image objects contain the actual voxel values, but also information on the number of voxels,\n",
    "voxel size, etc. There are methods to get this information.\n",
    "\n",
    "There are additional methods for other manipulations, such as basic image arithmetic (e.g.,\n",
    "you can add image objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in images\n",
    "Here we will read some images provided with the demo using the `ImageData` class.\n",
    "These are in Interfile format. (A text header called `something.hv` pointing to a `.v` file with the binary data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pet.ImageData('emission.hv')\n",
    "mu_map = pet.ImageData('attenuation.hv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an ImageData object?\n",
    "Images are represented by objects with several methods. Probably the most important method \n",
    "is `as_array()` which we'll use below.\n",
    "\n",
    "Let's see what all the methods are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pet.ImageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use as_array to extract an array of voxel values\n",
    "# The resulting array as a `numpy` array, as standard in Python.\n",
    "image_array=image.as_array()\n",
    "# We can use the standard `numpy` methods on this array, such as getting its `shape` (i.e. dimensions).\n",
    "print(image_array.shape)\n",
    "# Whenever we want to do something with the image-values, we have to do it via this array.\n",
    "# Let's print a voxel-value.\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Manipulate the image data for illustration\n",
    "# Multiply the data with a factor\n",
    "image_array *= 0.01\n",
    "# Stick this new data into the original image object.\n",
    "# (This will not modify the file content, only the variable in memory.)\n",
    "image.fill(image_array)\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% You can do basic math manipulations with ImageData objects \n",
    "# So the above lines can be done directly on the `image` object\n",
    "image *= 0.01\n",
    "# Let's check\n",
    "image_array=image.as_array()\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display the middle slice of the image (which is really a 3D volume)\n",
    "\n",
    "# Get the middle slice number\n",
    "slice_num = image_array.shape[0]//2\n",
    "# Display the slice using the `ImageData.show` method\n",
    "image.show(slice_num, title='emission image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when using the `%matplotlib widget` or `inline` back-ends, the `title` is currently not shown when using `show`. Apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Some other things to do with ImageData objects\n",
    "print(image.voxel_sizes())\n",
    "another_image=image.clone()\n",
    "an_image_with_fixed_values = image.get_uniform_copy(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and back projection\n",
    "Now we will do some PET projections!\n",
    "SIRF uses AcquisitionModel as the object to do forward and back-projections.\n",
    "We will create an AcquisitionModel object and then use it to forward project\n",
    "our image etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a SIRF acquisition model\n",
    "We will use the ray-tracing matrix here as our simple PET model.\n",
    "There is more to the accquisition model, but that's for another demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = pet.AcquisitionModelUsingRayTracingMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to say what scanner to use, what dimensions etc.\n",
    "The easiest way to do this by using existing PET data as a 'template'. \n",
    "Here, we read a file supplied with the demo as an `AcquisitionData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templ = pet.AcquisitionData('template_sinogram.hs')\n",
    "# Now set-up our acquisition model with all information that it needs about the data and image.\n",
    "am.set_up(templ,image); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning*: the provided template has no actual data, and is essentially only a header. Therefore, most operations using the `templ` variable would fail. However, it is sufficient for getting geometry etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AcquisitionModel` is now ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a forward projection of our image\n",
    "'forward projection' is the terminology used in PET to simulate the acquisition.\n",
    "Input is a SIRF `ImageData` object (not image_array), output is an `AcquisitionData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired_data=am.forward(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what methods an `AcquisitionData` object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(acquired_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AcquisitionData are 4D, organised by time-of-flight (TOF), (2D) sinograms, views and radial positions. Note that there is no TOF in this template, so the first dimension has size 1.\n",
    "\n",
    "(In fact, SIRF 3.4 does not provide TOF functionality yet, but this makes sure that dimensions will of PET `AcquisitionData` will remain 4D once we have added TOF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Let's get the Python array\n",
    "acquisition_array = acquired_data.as_array()\n",
    "print(acquisition_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, this data is very small. That means that future exercises will be fast, but also that resolution is going to be bad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display bitmap of the middle sinogram\n",
    "# The sinogram index is the second dimension of an array (but Python counts from 0...)\n",
    "sino_num = acquisition_array.shape[1]//2\n",
    "acquired_data.show(sino_num,title='Forward projection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some different 'views' in a movie.\n",
    "\n",
    "If the animation doesn't work, you might have to change your \"backend\", e.g. using the `%matplotlib` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmaps=[]\n",
    "fig=plt.figure()\n",
    "# views are the third index in the data\n",
    "num_views=acquisition_array.shape[2]\n",
    "# first construct all the plots\n",
    "for view in range(0,num_views,4):\n",
    "    bitmap=plt.imshow(acquisition_array[0,:,view,:,])\n",
    "    plt.clim(0,acquisition_array.max())\n",
    "    plt.axis('off')\n",
    "    bitmaps.append([bitmap])\n",
    "# Display as animation\n",
    "ani = animation.ArtistAnimation(fig, bitmaps, interval=100, blit=True, repeat_delay=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recognise projections of the bottom half of the brain in that animation (with the bottom displayed at the top!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprojection\n",
    "Backprojection multiplies projectino data with the transpose of the forward-projection matrix to go from `AcquisitionData` to an `ImageData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprojected = am.backward(acquired_data)\n",
    "backprojected.show(slice_num, title='backprojection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could have a look at the files that were generated or copied, in particular the `.hs` and `.hv` headers to see if you can make (a little bit of) sense of them. Some of the sizes etc above should be in those headers of course. You can do this by using `File>Open` menu of the Jupyter interface and navigating to the current working directory. Let's print it out again as a reminder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could try and repeat this with the `brainweb` data, using some of the code of the \"Introductory\" notebooks, and see if you can make sense of the animations, sizes etc.\n",
    "\n",
    "This could go as follows:\n",
    "  1. create a template for a full mMR acquisition\n",
    "   ```\n",
    "   templ = pet.AcquisitionData(os.path.join(examples_data_path('PET'), 'mMR','mMR_template_span11.hs'))\n",
    "   ```\n",
    "  2. create im_pet as in the introduction notebook\n",
    "\n",
    "  3. create acquisition model and use it as above\n",
    "  \n",
    "Once done, have a look at the [Synergistic/BrainWeb notebook](../Synergistic/BrainWeb.ipynb) for a complete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suggest you then try the [image_creation_and_simulation notebook](image_creation_and_simulation.ipynb), which constructs images with geometrical objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
