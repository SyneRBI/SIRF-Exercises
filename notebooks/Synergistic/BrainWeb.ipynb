{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data based on BrainWeb images\n",
    "\n",
    "From brainweb, get: \n",
    "- Two PET images\n",
    "    - FDG\n",
    "    - Amyloid\n",
    "- Two MR acquisitions:\n",
    "    - T1\n",
    "    - T2\n",
    "- A $\\mu$-map\n",
    "\n",
    "We're going to do various things with the images to create some data we can play around with! In image space, this includes:\n",
    "- adding misalignment to some images (amyloid and its $\\mu$-map)\n",
    "- adding tumours\n",
    "\n",
    "And then forward projecting all of this data to end up with:\n",
    "- Noisy and noiseless sinograms with and without misalignment, and with and without a tumour\n",
    "\n",
    "This data is used in some of the other synergistic notebooks.\n",
    "\n",
    "Acquiring the brainweb data is done via Casper da Costa-Luis' wrapper as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Richard Brown, Casper da Costa-Luis, Kris Thielemans  \n",
    "First version: 2nd of November 2019  \n",
    "Seconf version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019, 2021  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Synergistic Reconstruction for Biomedical Imaging.\n",
    "(http://www.synerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "\n",
    "import brainweb\n",
    "from brainweb import volshow\n",
    "import numpy as np\n",
    "from os import path, mkdir, chdir\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import nibabel as nib\n",
    "import sirf.STIR as pet\n",
    "import matplotlib.pyplot as plt\n",
    "import sirf.Reg as reg\n",
    "from math import cos, sin, pi\n",
    "from sirf.Utilities import examples_data_path\n",
    "from sirf_exercises import exercises_data_path\n",
    "import shutil\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "wd = path.join(exercises_data_path('Synergistic'), \"Brainweb\")\n",
    "try:\n",
    "    mkdir(wd)\n",
    "except:\n",
    "    print(\"Brainweb data path exists\")\n",
    "chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get brainweb data (just single patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, url= sorted(brainweb.utils.LINKS.items())[0]\n",
    "files = brainweb.get_file(fname, url, \".\")\n",
    "data = brainweb.load_file(fname)\n",
    "\n",
    "brainweb.seed(1337)\n",
    "\n",
    "for f in tqdm([fname], desc=\"mMR ground truths\", unit=\"subject\"):\n",
    "    vol = brainweb.get_mmr_fromfile(\n",
    "        f,\n",
    "        petNoise=1, t1Noise=0.75, t2Noise=0.75,\n",
    "        petSigma=1, t1Sigma=1, t2Sigma=1)\n",
    "    vol_amyl = brainweb.get_mmr_fromfile(\n",
    "        f,\n",
    "        petNoise=1, t1Noise=0.75, t2Noise=0.75,\n",
    "        petSigma=1, t1Sigma=1, t2Sigma=1,\n",
    "        PetClass=brainweb.Amyloid)\n",
    "\n",
    "FDG_arr  = vol['PET']\n",
    "amyl_arr = vol_amyl['PET']\n",
    "uMap_arr = vol['uMap']\n",
    "T1_arr   = vol['T1']\n",
    "T2_arr   = vol['T2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure();\n",
    "slice_show = FDG_arr.shape[0]//2\n",
    "subplot_([2,3,1],FDG_arr [slice_show, 100:-100, 100:-100],'FDG'    ,cmap=\"hot\")\n",
    "subplot_([2,3,2],amyl_arr[slice_show, 100:-100, 100:-100],'Amyloid',cmap=\"hot\")\n",
    "subplot_([2,3,3],uMap_arr[slice_show, 100:-100, 100:-100],'uMap'   ,cmap=\"bone\")\n",
    "subplot_([2,3,4],T1_arr  [slice_show, 100:-100, 100:-100],'T1'     ,cmap=\"Greys_r\")\n",
    "subplot_([2,3,5],T2_arr  [slice_show, 100:-100, 100:-100],'T2'     ,cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images and save\n",
    "\n",
    "Here's what's going on in this cell:\n",
    "\n",
    "1. The data from brainweb is (127,344,344), but we want it to be (127,285,285). So just keep the middle sections of the image in the x-y plane.\n",
    "2. Save the image to file.\n",
    "3. Crop the image yet again to reduce it to (127,150,150). You can use either of these two sets of images, but it'll be faster to use the smaller image. We'll also apply a shift of (25,25) in the x-y plane to re-centre the image.\n",
    "4. Save the smaller image to file, too.\n",
    "\n",
    "N.B.: This requires you to have a version of SIRF > v2.1.0. See the cell at the bottom of this notebook if you have an older version of SIRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need a template sinogram\n",
    "mMR_template_sino = examples_data_path('PET') + \"/mMR/mMR_template_span11.hs\"\n",
    "templ_sino = pet.AcquisitionData(mMR_template_sino)\n",
    "\n",
    "def crop_and_save(templ_sino, vol, fname):\n",
    "    # Crop from (127,344,344) to (127,285,285) and save to file\n",
    "    vol = vol[:,17:17+285,17:17+285]\n",
    "    im = pet.ImageData(templ_sino)\n",
    "    im.fill(vol)\n",
    "    im.write(fname)\n",
    "    # Create an optional smaller version, (127,150,150)\n",
    "    # For extra speeeed.\n",
    "    # Also shift by (25,25) in (x,y) to recentre the image\n",
    "    im = im.zoom_image(size=(-1,150,150),offsets_in_mm=(0,25,25))\n",
    "    im = im.move_to_scanner_centre(templ_sino)\n",
    "    im.write(fname + \"_small.hv\")\n",
    "    return im\n",
    "    \n",
    "FDG  = crop_and_save(templ_sino, FDG_arr,  \"FDG\"    )\n",
    "amyl = crop_and_save(templ_sino, amyl_arr, \"Amyloid\")\n",
    "uMap = crop_and_save(templ_sino, uMap_arr, \"uMap\"   )\n",
    "T1   = crop_and_save(templ_sino, T1_arr,   \"T1\"     )\n",
    "T2   = crop_and_save(templ_sino, T2_arr,   \"T2\"     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "slice_show = FDG.as_array().shape[0]//2\n",
    "subplot_([2,3,1],FDG.as_array() [slice_show,:,:],'FDG'    ,cmap=\"hot\")\n",
    "subplot_([2,3,2],amyl.as_array()[slice_show,:,:],'Amyloid',cmap=\"hot\")\n",
    "subplot_([2,3,3],uMap.as_array()[slice_show,:,:],'uMap'   ,cmap=\"bone\")\n",
    "subplot_([2,3,4],T1.as_array()  [slice_show,:,:],'T1'     ,cmap=\"Greys_r\")\n",
    "subplot_([2,3,5],T2.as_array()  [slice_show,:,:],'T2'     ,cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward project\n",
    "\n",
    "Forward project both the FDG and amyloid images both with and without Poisson noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acquisition_model(templ_sino, uMap, global_factor=.01):\n",
    "    '''create an acq_model given a mu-map and a global sensitivity factor\n",
    "    \n",
    "    The default global_factor is chosen such that the mean values of the\n",
    "    forward projected BrainWeb data have a reasonable magnitude\n",
    "    '''\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    # Let's use a fairly large number of rays to have a more realistic model\n",
    "    am.set_num_tangential_LORs(10)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(uMap, am)\n",
    "    asm_attn.set_up(templ_sino)\n",
    "    bin_eff = templ_sino.get_uniform_copy(global_factor)\n",
    "    print('applying attenuation (please wait, may take a while)...')\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    am.set_acquisition_sensitivity(asm)\n",
    "    return am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding noise\n",
    "def add_noise(proj_data,noise_factor = 1):\n",
    "    proj_data_arr = proj_data.as_array() / noise_factor\n",
    "    # Data should be >=0 anyway, but add abs just to be safe\n",
    "    proj_data_arr = np.abs(proj_data_arr)\n",
    "    noisy_proj_data_arr = np.random.poisson(proj_data_arr).astype('float32');\n",
    "    noisy_proj_data = proj_data.get_uniform_copy()\n",
    "    noisy_proj_data.fill(noisy_proj_data_arr);\n",
    "    return noisy_proj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = get_acquisition_model(templ_sino, uMap)\n",
    "am.set_up(templ_sino, FDG)\n",
    "\n",
    "# FDG\n",
    "sino_FDG = am.forward(FDG)\n",
    "sino_FDG.write(\"FDG_sino\")\n",
    "sino_FDG_noisy = add_noise(sino_FDG)\n",
    "sino_FDG_noisy.write(\"FDG_sino_noisy\")\n",
    "\n",
    "# Amyloid\n",
    "sino_amyl = am.forward(amyl)\n",
    "sino_amyl.write(\"amyl_sino\")\n",
    "sino_amyl_noisy = add_noise(sino_amyl)\n",
    "sino_amyl_noisy.write(\"amyl_sino_noisy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "subplot_([2,2,1],       sino_FDG.as_array()[0,60,:,:],'FDG'          )\n",
    "subplot_([2,2,2], sino_FDG_noisy.as_array()[0,60,:,:],'Noisy FDG'    )\n",
    "subplot_([2,2,3],      sino_amyl.as_array()[0,60,:,:],'Amyloid'      )\n",
    "subplot_([2,2,4],sino_amyl_noisy.as_array()[0,60,:,:],'Noisy amyloid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a rigid transformation to the amyloid image.\n",
    "Here we illustrate how to reposition the images using `sirf.Reg`. This data could be used to check what happens if there is a misalignment with the anatomical image in guided reconstruction, or between 2 PET images (see the [Dual_PET notebook](Dual_PET.ipynb). You could just come back to this notebook when you need this data of course.\n",
    "\n",
    "As with the crop, moving an image around affects its offset in STIR, which currently causes problems. So again, we recentre the image after the resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_misalignment(transformation_matrix,image):\n",
    "\n",
    "    # Resample\n",
    "    resampler = reg.NiftyResample()\n",
    "    resampler.set_interpolation_type_to_cubic_spline()\n",
    "    resampler.set_reference_image(image)\n",
    "    resampler.set_floating_image(image)\n",
    "    resampler.set_padding_value(0)\n",
    "    resampler.add_transformation(transformation_matrix)\n",
    "    resampler.process()\n",
    "\n",
    "    # Save to file\n",
    "    resampled = resampler.get_output()\n",
    "\n",
    "    # Remove all offset info (avoids problems in STIR)\n",
    "    misaligned_image = resampled.move_to_scanner_centre(templ_sino)\n",
    "    return misaligned_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the transformation matrix\n",
    "\n",
    "The rotation matrix we'll use here is a rotation of 30 degrees about one of the axes, and a translation of 20 and -10 mm in the x- and y-directions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation matrix\n",
    "r = 10*pi/180\n",
    "t_x = 20\n",
    "t_y = -10\n",
    "\n",
    "tm = reg.AffineTransformation(np.array(\\\n",
    "        [[ cos(r), sin(r), 0, t_x], \\\n",
    "         [-sin(r), cos(r), 0, t_y], \\\n",
    "         [      0,      0, 1, 0  ], \\\n",
    "         [      0,      0, 0, 1  ]]))\n",
    "\n",
    "amyl_misaligned = add_misalignment(tm,amyl)\n",
    "uMap_misaligned = add_misalignment(tm,uMap)\n",
    "\n",
    "amyl_misaligned.write(\"amyl_misaligned\")\n",
    "uMap_misaligned.write(\"uMap_misaligned\")\n",
    "\n",
    "plt.figure()\n",
    "subplot_([2,2,1],amyl.as_array()[60,:,:],'Amyloid')\n",
    "subplot_([2,2,2],uMap.as_array()[60,:,:],'uMap')\n",
    "subplot_([2,2,3],amyl_misaligned.as_array()[60,:,:],'Resampled Amyloid')\n",
    "subplot_([2,2,4],uMap_misaligned.as_array()[60,:,:],'Resampled uMap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Forward project this data. Note that we need a new acquisition model, as the attenuation image has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get acquisition model for resampled data\n",
    "am_misaligned = get_acquisition_model(templ_sino, uMap_misaligned)\n",
    "am_misaligned.set_up(templ_sino, amyl_misaligned)\n",
    "# Forward project again\n",
    "sino_amyl_misaligned = am_misaligned.forward(amyl_misaligned)\n",
    "sino_amyl_misaligned.write(\"amyl_sino_misaligned\")\n",
    "sino_amyl_noisy_misaligned = add_noise(sino_amyl_misaligned)\n",
    "sino_amyl_noisy_misaligned.write(\"amyl_sino_noisy_misaligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "subplot_([2,2,1],sino_amyl.as_array()[0,60,:,:],'Amyloid')\n",
    "subplot_([2,2,2],sino_amyl_noisy.as_array()[0,60,:,:],'Noisy amyloid')\n",
    "subplot_([2,2,3],sino_amyl_misaligned.as_array()[0,60,:,:],'Amyloid resampled')\n",
    "subplot_([2,2,4],sino_amyl_noisy_misaligned.as_array()[0,60,:,:],'Noisy resampled amyloid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert tumour\n",
    "\n",
    "We add a spherical tumour into the FDG image. Then we forward project it and add Poisson noise. The results of would be useful to check the effect in synergistic (or guided) reconstruction. The data is currently used in the HKEM notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an image filled with zeroes. \n",
    "tumour_arr = FDG.get_uniform_copy(0).as_array()\n",
    "# The value of the tumour will be 1.2*the max in the FDG image\n",
    "tumour_val = 1.2 * FDG.max()\n",
    "# Give the radius of the tumour\n",
    "tumour_radius_in_voxels = 4\n",
    "# Amount of smoothing\n",
    "gaussian_sigma = 1\n",
    "# Index of centre of the tumour\n",
    "tumour_centre = np.array([60, 50, 90])\n",
    "# Loop over all voxels in the cube containing the sphere\n",
    "for i in range(-tumour_radius_in_voxels, tumour_radius_in_voxels):\n",
    "    for j in range(-tumour_radius_in_voxels, tumour_radius_in_voxels):\n",
    "        for k in range(-tumour_radius_in_voxels, tumour_radius_in_voxels):\n",
    "            # If the index is inside of the sphere, set the tumour value\n",
    "            if (i*i+j*j+k*k < tumour_radius_in_voxels*tumour_radius_in_voxels):\n",
    "                tumour_arr[tumour_centre[0]+i,tumour_centre[1]+j,tumour_centre[2]+k] = tumour_val\n",
    "\n",
    "# Smooth the tumour image\n",
    "tumour_arr = gaussian_filter(tumour_arr, sigma=gaussian_sigma)\n",
    "\n",
    "# Overwrite add\n",
    "tumour_arr = np.max([FDG.as_array(),tumour_arr],axis=0)\n",
    "\n",
    "# Fill into new ImageData object\n",
    "pet_tumour = FDG.clone()\n",
    "pet_tumour.fill(tumour_arr)\n",
    "pet_tumour.write('FDG_tumour')\n",
    "\n",
    "# Show side by side\n",
    "plt.figure();\n",
    "subplot_([1,2,1],FDG.as_array()[60,:,:],\"PET without tumour\", [0,tumour_arr.max()])\n",
    "subplot_([1,2,2],tumour_arr[60,:,:],\"PET tumour\",[0,tumour_arr.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward project FDG image with tumour\n",
    "umap_small=pet.ImageData('uMap_small.hv')\n",
    "am = get_acquisition_model(templ_sino, umap_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDG\n",
    "am.set_up(templ_sino,pet_tumour)\n",
    "sino_tumour_FDG = am.forward(pet_tumour)\n",
    "sino_tumour_FDG.write(\"FDG_tumour_sino\")\n",
    "sino_tumour_FDG_noisy = add_noise(sino_tumour_FDG)\n",
    "sino_tumour_FDG_noisy.write(\"FDG_tumour_sino_noisy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping with SIRF <= v2.1.0\n",
    "\n",
    "`zoom_image` and `move_to_scanner_centre` didn't exist prior to SIRF v2.1.0. If your version is older see this link for some help: https://github.com/SyneRBI/SIRF-Exercises/issues/52. Good luck, soldier!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
