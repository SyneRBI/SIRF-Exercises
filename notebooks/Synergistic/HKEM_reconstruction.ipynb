{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the Hybrid Kernelised Expection Maximisation (HKEM) reconstruction with SIRF\n",
    "This demonstration shows how to use HKEM and investigate the role of each kernel parameter in edge preservation and noise suppression.\n",
    "\n",
    "While this notebook doesn't do a complete parameter search, it does do quite a few reconstructions. You could therefore first run it through completely, and then come back to check the results. Note that if you do that, some of the plots might not show. You can then just re-run those cells.\n",
    "\n",
    "N.B.: You need to have run the [BrainWeb](./BrainWeb.ipynb) notebook first to generate the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Daniel Deidda, Kris Thielemans, Evgueni Ovtchinnikov, Richard Brown  \n",
    "First version: 30th of September 2019  \n",
    "Second version: 6th of November 2019  \n",
    "Thierd version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019, 2021  National Physical Laboratory  \n",
    "Copyright 2019  Rutherford Appleton Laboratory STFC  \n",
    "Copyright 2019, 2021  University College London\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Synergistic Reconstruction for Biomedical Imaging.\n",
    "(http://www.synerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HKEM brief description\n",
    "The Kernel Expectation Maximisation (KEM) method was suggested in  \n",
    "Wang, Guobao, and Jinyi Qi. ‘PET Image Reconstruction Using Kernel Method’. IEEE Transactions on Medical Imaging 34, no. 1 (January 2015): 61–71. https://doi.org/10.1109/TMI.2014.2343916.\n",
    "\n",
    "The main idea was to use \"kernels\" (constructed based on another image such as an MR image) to construct \"basis functions\" for the PET reconstruction. The reconstruction estimates the PET image as a linear combination of these kernels.\n",
    "\n",
    "One of the potential problems with KEM is what happens if there are unique features in the PET image, which are not present in the \"guidance\" (i.e. the MR image). If the MR-derived kernels are too \"wide\", there is a danger that the PET-unique features are suppressed.\n",
    "\n",
    "To overcome this problem, Deidda *et al.* developed the Hybrid KEM method, see  \n",
    "Deidda, Daniel, Nicolas A. Karakatsanis, Philip M. Robson, Yu-Jung Tsai, Nikos Efthimiou, Kris Thielemans, Zahi A. Fayad, Robert G. Aykroyd, and Charalampos Tsoumpas. ‘Hybrid PET-MR List-Mode Kernelized Expectation Maximization Reconstruction’. Inverse Problems 35, no. 4 (March 2019): 044001. https://doi.org/10.1088/1361-6420/ab013f.\n",
    "\n",
    "The main idea here is to compute new kernels at every image update. These kernels are \"hybrids\" between the MR and (current) PET image. This way, if there is a PET feature, it will gradually influence the kernels and therefore no longer suppress it. (Or at least, that's what the authors hope!)\n",
    "\n",
    "Implementing HKEM in SIRF would be rather involved. Luckily, Daniel Deidda did the hard work for you and implemented it in STIR (with help from a few others). `sirf.STIR.KOSMAPOSL` wraps this STIR implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** Currently the reconstructions in this notebook take a long time (around 4 minutes per reconstruction on descent hardware). You could use smaller data (a scanner with fewer slices) or use larger voxel sizes/fewer voxels.\n",
    "In its current form, we recomment you run the whole notebook, and then look at the plots afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib widget\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('Synergistic', 'HKEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import string\n",
    "#import scipy\n",
    "#from scipy import optimize\n",
    "import sirf.STIR as pet\n",
    "from sirf_exercises import exercises_data_path\n",
    "\n",
    "brainweb_sim_data_path = exercises_data_path('working_folder', 'Synergistic', 'BrainWeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up redirection of STIR messages to files\n",
    "msg_red = pet.MessageRedirector('info.txt', 'warnings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% some handy function definitions\n",
    "def imshow_hot(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image, cmap=\"hot\")\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.3)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def imshow(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.3)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def imshow_gray(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image, cmap=\"gray\")\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.3)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_positive(image_array):\n",
    "    \"\"\"truncate any negatives to zero\"\"\"\n",
    "    image_array[image_array<0] = 0\n",
    "    return image_array\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filter = pet.TruncateToCylinderProcessor()\n",
    "    filter.apply(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data and set some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data we generated previously in BrainWeb.ipynb\n",
    "full_sino = pet.AcquisitionData(os.path.join(brainweb_sim_data_path, 'FDG_tumour_sino_noisy.hs'))\n",
    "\n",
    "atten = pet.ImageData(os.path.join(brainweb_sim_data_path, 'uMap_small.hv'))\n",
    "\n",
    "# Anatomical image\n",
    "anatomical = pet.ImageData(os.path.join(brainweb_sim_data_path, 'T2_small.hv')).abs()\n",
    "\n",
    "#%%  create initial image\n",
    "init_image=anatomical.get_uniform_copy(1)\n",
    "make_cylindrical_FOV(init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pet.ImageData(os.path.join(brainweb_sim_data_path, 'FDG_tumour.hv'))\n",
    "image_array = image.as_array()\n",
    "#%% save max for future displays\n",
    "cmax = image_array.max()*.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show anatomical image and true image\n",
    "anatomical_array=anatomical.as_array()\n",
    "atten_array=atten.as_array()\n",
    "im_slice = 62 #atten_array.shape[0]//2\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "imshow_gray(anatomical_array[im_slice,:,:,], [0,220],'Anatomical image')\n",
    "plt.subplot(1,2,2)\n",
    "imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the acquisition model and objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first use the `rebin` functionality to create smaller acquisition data to speed up calculations.\n",
    "The line below will keep only \"segment\" 0.\n",
    "\n",
    "If you want to make things faster you can rebin your data by compressing axial and view bins.\n",
    "Of course, this will affect the quality of the reconstructed images somewhat.\n",
    "\n",
    "If you have enough computational power you can try setting `max_in_segment_num_to_process` higher (or even do `sino=full_sino`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(full_sino.rebin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sino = full_sino.rebin(1, num_views_to_combine=1,max_in_segment_num_to_process=0,do_normalisation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A copy of the function in the BrainWeb notebook, except that we set the number of LORs to tracer per bin a bit lower (to avoid using too much of an inverse crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acquisition_model(uMap, templ_sino, global_factor=.01):\n",
    "    '''create an acq_model given a mu-map and a global sensitivity factor\n",
    "    \n",
    "    The default global_factor is chosen such that the mean values of the\n",
    "    forward projected BrainWeb data have a reasonable magnitude\n",
    "    '''\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(uMap, am)\n",
    "    asm_attn.set_up(templ_sino)\n",
    "    bin_eff = templ_sino.get_uniform_copy(global_factor)\n",
    "    print('applying attenuation (please wait, may take a while)...')\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    am.set_acquisition_sensitivity(asm)\n",
    "    return am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am=get_acquisition_model(atten,sino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create objective function\n",
    "obj_fun = pet.make_Poisson_loglikelihood(sino)\n",
    "obj_fun.set_acquisition_model(am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  create KOSMAPOSL reconstructor\n",
    "`sirf.STIR.KOSMAPOSL` implements the Ordered Subsets HKEM (if you do not add an additional prior).\n",
    "\n",
    "In this section we define all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = pet.KOSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "\n",
    "recon.set_anatomical_prior(anatomical)\n",
    "recon.set_num_non_zero_features(1)\n",
    "recon.set_num_subsets(21)\n",
    "recon.set_num_subiterations(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_m (MR edge preservation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1m_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "sigma_m={0.05, 0.2, 1}\n",
    "ii=0\n",
    "for i in sigma_m:\n",
    "\n",
    "    H1m_reconstructed_image.append(init_image.clone())\n",
    "    \n",
    "    recon.set_sigma_m(i)\n",
    "\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1m_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1m_reconstructed_image[ii])\n",
    "\n",
    "\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% bitmap display of images\n",
    "# definea lists\n",
    "H1m_reconstructed_array = []\n",
    "H1m_error_array = []\n",
    "\n",
    "ii=0\n",
    "\n",
    "for i in sigma_m:\n",
    "\n",
    "    H1m_reconstructed_array.append(H1m_reconstructed_image[ii].as_array())\n",
    "    H1m_error_array.append(image_array - H1m_reconstructed_array[ii])\n",
    "    \n",
    "  \n",
    "    j=\"{}\".format(i)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1m_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_m='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1m_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_p (PET edge preservation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1p_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "sigma_p={0.05, 2}\n",
    "ii=0\n",
    "for i in sigma_p:\n",
    "\n",
    "    H1p_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_sigma_p(i)\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1p_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1p_reconstructed_image[ii])\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1p_reconstructed_image.append(H1p_reconstructed_image[1])\n",
    "#%% bitmap display of images\n",
    "# define lists\n",
    "H1p_reconstructed_array = []\n",
    "H1p_error_array = []\n",
    "ii=0\n",
    "sigma_p={0.05, 2,0.2}\n",
    "for i in sigma_p:\n",
    "\n",
    "    j=\"{}\".format(i)\n",
    "\n",
    "    H1p_reconstructed_array.append(H1p_reconstructed_image[ii].as_array())\n",
    "\n",
    "    H1p_error_array.append(image_array - H1p_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1p_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_p='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1p_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_d (smoothing, depends on the voxel size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1d_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "\n",
    "sigma_dm={0.5, 1}\n",
    "ii=0\n",
    "for i in sigma_dm:\n",
    "\n",
    "    H1d_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_sigma_dp(i)\n",
    "    recon.set_sigma_dm(i)\n",
    "\n",
    "   #   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1d_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1d_reconstructed_image[ii])\n",
    "\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1d_reconstructed_image.append(H1m_reconstructed_image[1])\n",
    "#%% bitmap display of images\n",
    "# define lists\n",
    "H1d_reconstructed_array = []\n",
    "H1d_error_array = []\n",
    "ii=0\n",
    "sigma_dm={0.5, 1, 5}\n",
    "for i in sigma_dm:\n",
    "\n",
    "    j=\"{}\".format(i)\n",
    "\n",
    "    H1d_reconstructed_array.append(H1d_reconstructed_image[ii].as_array())\n",
    "\n",
    "#   anatomical_image_array = anatomical_image.as_array()\n",
    "    H1d_error_array.append(image_array - H1d_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1d_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_dm='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1d_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter \"neighbourhood size\", n\n",
    "try to rebin the data even more if it is too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1n_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "n={1, 5}\n",
    "ii=0\n",
    "for i in n:\n",
    "\n",
    "    H1n_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_num_neighbours(i)\n",
    "\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1n_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1n_reconstructed_image[ii])\n",
    "\n",
    "    ii=ii+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the n=3 case which we've done above\n",
    "# careful: zthe list will have `n` in a strange order (see below)\n",
    "H1n_reconstructed_image.append(H1m_reconstructed_image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% bitmap display of images\n",
    "# define lists\n",
    "\n",
    "H1n_reconstructed_array = []\n",
    "H1n_error_array = []\n",
    "n=[1, 5, 3]\n",
    "for ii in range(len(n)):\n",
    "\n",
    "    i=n[ii]\n",
    "    j=\"{}\".format(i)\n",
    "    \n",
    "    H1n_reconstructed_array.append(H1n_reconstructed_image[ii].as_array())\n",
    "\n",
    "#   anatomical_image_array = anatomical_image.as_array()\n",
    "    H1n_error_array.append(image_array - H1n_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1n_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'HKEM, N='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1n_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct  with KEM\n",
    "HKEM reduces to KEM  when setting hybrid to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEM image is: H0_reconstructed_array\n",
    "\n",
    "H0_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "H0_reconstructed_image.append(init_image.clone())\n",
    "recon.set_num_neighbours(5)\n",
    "\n",
    "#   set up the reconstructor\n",
    "recon.set_hybrid(False)\n",
    "recon.set_up(H0_reconstructed_image[0])\n",
    "recon.reconstruct(H0_reconstructed_image[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare HKEM and KEM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_reconstructed_array= H0_reconstructed_image[0].as_array()\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "imshow_hot(H0_reconstructed_array[im_slice,:,:,], [0,cmax*2.], 'KEM')\n",
    "plt.subplot(1,2,2)\n",
    "imshow_hot(H1n_reconstructed_array[2][im_slice,:,:,], [0,cmax*2.], 'HKEM')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) what difference can you see when you change each parameter? and between HKEM and KEM?\n",
    "The above plots might give you some feeling for how the different parameters change the images. It would be better to do some quantitative measures such as a RMSE with the ground truth, or some ROI values (and in particular the tumour)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) what happens if there is misalignment between Anatomical image and PET image?\n",
    "\n",
    "There can be motion between the PET and anatomical images. If this misalignment is too large, clearly it will be disadvantageous to use it for \"guidance\". The effect was studied for HKEM in  \n",
    "Deidda, Daniel, N. A. Karakatsanis, Philip M. Robson, Nikos Efthimiou, Zahi A. Fayad, Robert G. Aykroyd, and Charalampos Tsoumpas. ‘Effect of PET-MR Inconsistency in the Kernel Image Reconstruction Method’. IEEE Transactions on Radiation and Plasma Medical Sciences 3, no. 4 (July 2019): 400–409. https://doi.org/10.1109/TRPMS.2018.2884176.\n",
    "\n",
    "You can try to reproduce some of that investigation using the following steps:\n",
    "- you can create misalignment by shifting or rotation the anatomical image like in the [BrainWeb notebook ](BrainWeb.ipynb)\n",
    "- set `KOSMAPOSL` reconstructor to use the new anatomical image and reconstruct as above. \n",
    "- plot images, or investigate ROI values, e.g. in the tumour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Try to resolve the misalignment before running HKEM\n",
    "Run an OSEM reconstruction and align the anatomical image from the previous exercise with the OSEM image. You can use `sirf.Reg` for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar exercises can be done using other algorithms that use anatomical information.\n",
    "You could have a look at the [MAPEM_Bowsher notebook](MAPEM_Bowsher.ipynb) and repeat these exercises and compare results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
