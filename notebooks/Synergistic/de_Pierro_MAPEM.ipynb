{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPEM de Pierro algorithm\n",
    "\n",
    "Authors: Kris Thielemans, Sam Ellis, Richard Brown, Casper da Costa-Luis  \n",
    "First version: 22nd of October 2019  \n",
    "Second version: 27th of October 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with [PET/MAPEM](../PET/MAPEM.ipynb)...\n",
    "\n",
    "If you've already completed the PET component, you will have implemented a version of MAPEM. If you haven't, you'll probably want to give that a go first!\n",
    "\n",
    "This example extends upon the quadratic prior used in that notebook to use an anatomical prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the normal imports and handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm.auto import tqdm, trange\n",
    "from numba import jit\n",
    "import time\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import examples_data_path\n",
    "# plotting settings\n",
    "plt.ion() # interactive 'on' such that plots appear during loops\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "#%% some handy function definitions\n",
    "def imshow(image, limits=None, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if limits is None:\n",
    "        limits = [image.min(), image.max()]\n",
    "                \n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filt = pet.TruncateToCylinderProcessor()\n",
    "    filt.apply(image)\n",
    "\n",
    "#%% define a function for plotting images and the updates\n",
    "# This is the same function as in `ML_reconstruction`\n",
    "def plot_progress(all_images, title, subiterations, cmax):\n",
    "    if len(subiterations)==0:\n",
    "        num_subiters = all_images[0].shape[0]-1\n",
    "        subiterations = range(1, num_subiters+1)\n",
    "    num_rows = len(all_images);\n",
    "    slice_show = 60\n",
    "    for it in subiterations:\n",
    "        plt.figure()\n",
    "        for r in range(num_rows):\n",
    "            plt.subplot(num_rows,2,2*r+1)\n",
    "            imshow(all_images[r][it,slice_show,:,:], [0,cmax], '%s at %d' % (title[r],  it))\n",
    "            plt.subplot(num_rows,2,2*r+2)\n",
    "            imshow(all_images[r][it,slice_show,:,:]-all_images[r][it-1,slice_show,:,:],[-cmax*.1,cmax*.1], 'update')\n",
    "        plt.show();  \n",
    "        \n",
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "To generate the data needed for this notebook, run the [generate_data](./generate_data.ipynb) notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to correct directory\n",
    "os.chdir(examples_data_path('Synergistic'))\n",
    "\n",
    "# copy files to working folder and change directory to where the output files are\n",
    "shutil.rmtree('working_folder/dePierro_brainweb',True)\n",
    "shutil.copytree('brainweb','working_folder/dePierro_brainweb')\n",
    "os.chdir('working_folder/dePierro_brainweb')\n",
    "\n",
    "full_acquired_data = pet.AcquisitionData('FDG_sino_noisy.hs')\n",
    "atten = pet.ImageData('uMap_small.hv')\n",
    "\n",
    "# Anatomical image\n",
    "anatomical = pet.ImageData('T1_small.hv') # could be T2_small.hv\n",
    "anatomical_arr = anatomical.as_array()\n",
    "\n",
    "# create initial image\n",
    "init_image=atten.get_uniform_copy(atten.as_array().max()*.1)\n",
    "make_cylindrical_FOV(init_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from first MAPEM notebook\n",
    "\n",
    "The following chunk of code is copied and pasted more-or-less directly from the other notebook as a starting point. \n",
    "\n",
    "First, run the code chunk to get the results using the quadratic prior..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPEM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights as an array\n",
    "w=numpy.array([1.,0.,1.])\n",
    "# normalise to have sum 1\n",
    "w/=w.sum()\n",
    "\n",
    "# Define function for xreg. \n",
    "# Using jit gets computation time from 90 secs to 2!\n",
    "@jit\n",
    "def compute_xreg(image_array):\n",
    "    sizes=image_array.shape\n",
    "    image_reg= image_array*0 # make a copy first. Will then change values\n",
    "    for z in range(0,sizes[0]):\n",
    "        for y in range(0,sizes[1]):\n",
    "            for x in range(1,sizes[2]-1): # ignore first and last pixel for simplicity\n",
    "                for dx in (-1,0,1):\n",
    "                    image_reg[z,y,x] += w[dx+1]/2*(image_array[z,y,x]+image_array[z,y,x+dx])\n",
    "            \n",
    "    return image_reg\n",
    "\n",
    "# define a function that computes the MAP-EM update\n",
    "@jit\n",
    "def compute_MAPEM_update(xEM,xreg, beta):\n",
    "    return (2*xEM)/(numpy.sqrt((1 - beta*xreg)**2 + 4*beta*xEM) + (1 - beta*xreg) + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_fun(acquired_data, atten):\n",
    "    print('\\n------------- Setting up objective function')\n",
    "    #     #%% create objective function\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(atten, am)\n",
    "    asm_attn.set_up(acquired_data)\n",
    "    bin_eff = pet.AcquisitionData(acquired_data)\n",
    "    bin_eff.fill(1.0)\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    # Set sensitivity of the model and set up\n",
    "    am.set_acquisition_sensitivity(asm_attn)\n",
    "    am.set_up(acquired_data,atten);\n",
    "\n",
    "    #%% create objective function\n",
    "    obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
    "    obj_fun.set_acquisition_model(am)\n",
    "\n",
    "    print('\\n------------- Finished setting up objective function')\n",
    "    return obj_fun\n",
    "\n",
    "def get_reconstructor(num_subsets, num_subiters, obj_fun, init_image):\n",
    "    print('\\n------------- Setting up reconstructor') \n",
    "\n",
    "    #%% create OSEM reconstructor\n",
    "    OSEM_reconstructor = pet.OSMAPOSLReconstructor()\n",
    "    OSEM_reconstructor.set_objective_function(obj_fun)\n",
    "    OSEM_reconstructor.set_num_subsets(num_subsets)\n",
    "    OSEM_reconstructor.set_num_subiterations(num_subiters)\n",
    "\n",
    "    #%% initialise\n",
    "    OSEM_reconstructor.set_up(init_image)\n",
    "    \n",
    "    print('\\n------------- Finished setting up reconstructor')\n",
    "    return OSEM_reconstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SSRB to create smaller sinogram to speed up calculations\n",
    "acquired_data = full_acquired_data.clone()\n",
    "acquired_data = acquired_data.rebin(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the objective function\n",
    "obj_fun = get_obj_fun(acquired_data, atten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets = 21\n",
    "num_subiters = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do a normal OSEM (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do initial OSEM recon\n",
    "OSEM_reconstructor = get_reconstructor(num_subsets, num_subiters, obj_fun, init_image)\n",
    "osem_image = init_image.clone()\n",
    "OSEM_reconstructor.reconstruct(osem_image)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(osem_image.as_array()[60,:,:])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do a normal MAPEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 10\n",
    "# We don't have to get a new reconstructor each time, \n",
    "# but if we don't, then we'll start from the same subiteration\n",
    "# that we finished last time. But we save a few seconds.\n",
    "# OSEM_reconstructor = get_reconstructor(num_subsets,num_subiters, obj_fun, init_image)\n",
    "\n",
    "#%% do a loop, saving images as we go along\n",
    "current_image = init_image.clone()\n",
    "all_images = numpy.ndarray(shape=(num_subiters+1,) + current_image.as_array().shape );\n",
    "all_images[0,:,:,:] =  current_image.as_array();\n",
    "\n",
    "for it in trange(1, num_subiters+1):\n",
    "    image_reg = compute_xreg(current_image.as_array()) # compute xreg\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    updated = compute_MAPEM_update(image_EM, image_reg, beta) # compute new update\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    all_images[it,:,:,:] =  updated; # save for plotting later on\n",
    "\n",
    "#%% now call this function to see how we went along\n",
    "subiterations = (1,2,4,8,16,32,42);\n",
    "plot_progress([all_images], ['Quadratic prior MAP-OSEM'],subiterations, all_images.max()*0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement de Pierro regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePierroReg(image,weights,nhoodIndVec):\n",
    "    \"\"\"Get the de Pierro regularisation image\"\"\"\n",
    "    imSize = image.shape\n",
    "    \n",
    "    # vectorise image for indexing \n",
    "    imageVec = image.reshape(-1,order='F')\n",
    "        \n",
    "    # retrieve voxel intensities for neighbourhoods \n",
    "    resultVec = imageVec[nhoodIndVec]\n",
    "    result = resultVec.reshape(weights.shape,order='F')\n",
    "    \n",
    "    # compute xreg\n",
    "    imageReg = 0.5*numpy.sum(weights*(result + image.reshape(-1,1,order='F')),axis=1)\n",
    "    imageReg = imageReg.reshape(imSize,order='F')\n",
    "    \n",
    "    return imageReg\n",
    "\n",
    "def compute_nhoodIndVec(image,weights):\n",
    "    \"\"\"Get the neigbourhoods of each voxel\"\"\"\n",
    "    weightsSize = weights.shape\n",
    "    w = int(round(weightsSize[1]**(1.0/3))) # side length of neighbourhood\n",
    "    nhoodInd    = neighbourExtract(image.shape,w)\n",
    "    return nhoodInd.reshape(-1,order='F')\n",
    "\n",
    "def neighbourExtract(imageSize,w):\n",
    "    \"\"\"Adapted from Prior class\"\"\"\n",
    "    n = imageSize[0]\n",
    "    m = imageSize[1]\n",
    "    h = imageSize[2]\n",
    "    wlen = 2*numpy.floor(w/2)\n",
    "    widx = xidx = yidx = numpy.arange(-wlen/2,wlen/2+1)\n",
    "\n",
    "    if h==1:\n",
    "        zidx = [0]\n",
    "        nN = w*w\n",
    "    else:\n",
    "        zidx = widx\n",
    "        nN = w*w*w\n",
    "        \n",
    "    Y,X,Z = numpy.meshgrid(numpy.arange(0,m), numpy.arange(0,n), numpy.arange(0,h))                \n",
    "    N = numpy.zeros([n*m*h, nN],dtype='int32')\n",
    "    l = 0\n",
    "    for x in xidx:\n",
    "        Xnew = setBoundary(X + x,n)\n",
    "        for y in yidx:\n",
    "            Ynew = setBoundary(Y + y,m)\n",
    "            for z in zidx:\n",
    "                Znew = setBoundary(Z + z,h)\n",
    "                N[:,l] = ((Xnew + (Ynew)*n + (Znew)*n*m)).reshape(-1,1).flatten('F')\n",
    "                l += 1\n",
    "    return N\n",
    "\n",
    "def setBoundary(X,n):\n",
    "    \"\"\"Boundary conditions for neighbourExtract.\n",
    "    Adapted from Prior class\"\"\"\n",
    "    idx = X<0\n",
    "    X[idx] = X[idx] + n\n",
    "    idx = X>n-1\n",
    "    X[idx] = X[idx] - n\n",
    "    return X.flatten('F')\n",
    "\n",
    "def dePierroUpdate(xEM, imageReg, beta):\n",
    "    \"\"\"Update the image based on the de Pierro regularisation image\"\"\"\n",
    "    return (2*xEM)/(((1 - beta*imageReg)**2 + 4*beta*xEM)**0.5 + (1 - beta*imageReg) + 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Prior for computing Bowsher weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.contrib.kcl.Prior as pr\n",
    "def update_bowsher_weights(prior,side_image,num_bowsher_neighbours):\n",
    "    weights = prior.BowshserWeights\\\n",
    "        (side_image.as_array(),num_bowsher_neighbours)/float(num_bowsher_neighbours)\n",
    "    return weights\n",
    "\n",
    "num_bowsher_neighbours = 7\n",
    "myPrior = pr.Prior(anatomical_arr.shape)\n",
    "weights = update_bowsher_weights(myPrior,anatomical,num_bowsher_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of the neighbourhood\n",
    "nhoodIndVec=compute_nhoodIndVec(atten,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate that only a few of the weights in the neighbourhood are kept\n",
    "# (taking an arbitrary voxel)\n",
    "print(weights[500,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable this to use uniform weights\n",
    "# weights[:]=1/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPEM_iteration(OSEM_reconstructor,current_image,weights,nhoodIndVec,beta):\n",
    "    image_reg = dePierroReg(current_image.as_array(),weights,nhoodIndVec) # compute xreg\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    updated = dePierroUpdate(image_EM, image_reg, beta) # compute new update\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    return current_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image=init_image.clone()\n",
    "all_images_deP = numpy.ndarray(shape=(num_subiters+1,) + current_image.as_array().shape )\n",
    "all_images_deP[0,:,:,:] =  current_image.as_array()\n",
    "\n",
    "for it in trange(1, num_subiters+1):\n",
    "    current_image = MAPEM_iteration(OSEM_reconstructor,current_image,weights,nhoodIndVec,beta)\n",
    "    \n",
    "    all_images_deP[it,:,:,:] =  current_image.as_array()  # save for plotting later on\n",
    "    \n",
    "#%% now call this function to see how we went along\n",
    "plt.figure()\n",
    "subiterations = (1,2,4,8,16,32,42)\n",
    "plot_progress([all_images_deP], ['Boswher MAP-OSEM'],subiterations, all_images_deP.max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the anatomical, OSEM, and two MAPEM \n",
    "plt.figure()\n",
    "subplot_([2,2,1],anatomical_arr[60,:,:],\"Anatomical\")\n",
    "subplot_([2,2,2],osem_image.as_array()[60,:,:],\"OSEM\")\n",
    "subplot_([2,2,3],all_images[num_subiters,60,:,:],\"Quadratic prior\")\n",
    "subplot_([2,2,4],all_images_deP[num_subiters,60,:,:],\"Bowsher prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, misalignment between anatomical and emission images?\n",
    "\n",
    "What happens if you want to use an anatomical prior but the image isn't aligned with the image you're trying to reconstruct?  \n",
    "\n",
    "You'll have to register them of course! Have a look at the [registration notebook](../Reg/sirf_registration.ipynb) if you haven't already.  \n",
    "\n",
    "The idea here would be to run an initial reconstruction (say, OSEM), and then register the anatomical image to the resulting reconstruction...\n",
    "\n",
    "Once we've got the anatomical image in the correct space, we can calculate the Bowsher weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.Reg as Reg\n",
    "\n",
    "registration = Reg.NiftyAladinSym()\n",
    "registration.set_reference_image\n",
    "registration.set_reference_image(osem_image)\n",
    "registration.set_floating_image(anatomical)\n",
    "registration.set_parameter('SetPerformRigid','1')\n",
    "registration.set_parameter('SetPerformAffine','0')\n",
    "registration.process()\n",
    "anatomical_in_emission_space = registration.get_output()\n",
    "\n",
    "weights = update_bowsher_weights(myPrior,anatomical_in_emission_space,num_bowsher_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were trying to do some sort of synergistic alternating reconstruction where motion was present, then we would probably want to try to somethings along the lines of:\n",
    "\n",
    "- Get the best looking images independently\n",
    "- Register the images\n",
    "- Extract forward and back transformations\n",
    "- The regularisation images evole as each others' side information evolves. \n",
    "- We therefore would need to resample into the target space before recalculating weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
