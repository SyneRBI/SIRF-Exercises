{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPEM de Pierro algorithm for the Bowsher prior\n",
    "One of the more popular methods for guiding a reconstruction based on a high quality image was suggested by Bowsher. This notebook explores this prior.\n",
    "\n",
    "We highly recommend you look at the [PET/MAPEM](../PET/MAPEM.ipynb) notebook first. This example extends upon the quadratic prior used in that notebook to use an anatomical prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Kris Thielemans, Sam Ellis, Richard Brown, Casper da Costa-Luis  \n",
    "First version: 22nd of October 2019  \n",
    "Second version: 27th of October 2019  \n",
    "Third version: June 2021\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019,20201  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Synergistic Reconstruction for Biomedical Imaging. (http://www.synerbi.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief description of the Bowsher prior\n",
    "The \"usual\" quadratic prior penalises differences between neighbouring voxels (using the square of the difference). This tends to oversmooth parts of the image where you know there should be an edge. To overcome this, it is natural to not penalise the difference between those \"edge\" voxels. This can be done after segmentation of the anatomical image for instance.\n",
    "\n",
    "Bowsher suggested a segmentation-free approach to use an anatomical (or any \"side\" image) as follows:\n",
    "- compute edge information on the anatomical image.\n",
    "- for each voxel, consider only the $N_B$ neighbours which have the lowest difference in the anatomical image.\n",
    "\n",
    "The paper is  \n",
    "Bowsher, J. E., Hong Yuan, L. W. Hedlund, T. G. Turkington, G. Akabani, A. Badea, W. C. Kurylo, et al. ‘Utilizing MRI Information to Estimate F18-FDG Distributions in Rat Flank Tumors’. In IEEE Symposium Conference Record Nuclear Science 2004., 4:2488-2492 Vol. 4, 2004. https://doi.org/10.1109/NSSMIC.2004.1462760.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the normal imports and handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('Synergistic', 'MAPEM_Bowsher')\n",
    "\n",
    "#%% Initial imports etc\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm.auto import tqdm, trange\n",
    "import time\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import sirf.STIR as pet\n",
    "from numba import jit\n",
    "from sirf_exercises import exercises_data_path\n",
    "\n",
    "brainweb_sim_data_path = exercises_data_path('working_folder', 'Synergistic', 'BrainWeb')\n",
    "# set-up redirection of STIR messages to files\n",
    "msg_red = pet.MessageRedirector('info.txt', 'warnings.txt', 'errors.txt')\n",
    "# plotting settings\n",
    "plt.ion() # interactive 'on' such that plots appear during loops\n",
    "\n",
    "#%% some handy function definitions\n",
    "def imshow(image, limits=None, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if limits is None:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filt = pet.TruncateToCylinderProcessor()\n",
    "    filt.apply(image)\n",
    "\n",
    "#%% define a function for plotting images and the updates\n",
    "# This is the same function as in `ML_reconstruction`\n",
    "def plot_progress(all_images, title, subiterations, cmax):\n",
    "    if len(subiterations)==0:\n",
    "        num_subiters = all_images[0].shape[0]-1\n",
    "        subiterations = range(1, num_subiters+1)\n",
    "    num_rows = len(all_images);\n",
    "    slice_show = 60\n",
    "    for it in subiterations:\n",
    "        plt.figure()\n",
    "        for r in range(num_rows):\n",
    "            plt.subplot(num_rows,2,2*r+1)\n",
    "            imshow(all_images[r][it,slice_show,:,:], [0,cmax], '%s at %d' % (title[r],  it))\n",
    "            plt.subplot(num_rows,2,2*r+2)\n",
    "            imshow(all_images[r][it,slice_show,:,:]-all_images[r][it-1,slice_show,:,:],[-cmax*.1,cmax*.1], 'update')\n",
    "        plt.show();  \n",
    "\n",
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "To generate the data needed for this notebook, run the [BrainWeb](./BrainWeb.ipynb) notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_acquired_data = pet.AcquisitionData(os.path.join(brainweb_sim_data_path, 'FDG_sino_noisy.hs'))\n",
    "atten = pet.ImageData(os.path.join(brainweb_sim_data_path, 'uMap_small.hv'))\n",
    "\n",
    "# Anatomical image\n",
    "anatomical = pet.ImageData(os.path.join(brainweb_sim_data_path, 'T1_small.hv')) # could be T2_small.hv\n",
    "anatomical_arr = anatomical.as_array()\n",
    "\n",
    "# create initial image\n",
    "init_image=atten.get_uniform_copy(atten.as_array().max()*.1)\n",
    "make_cylindrical_FOV(init_image)\n",
    "\n",
    "plt.figure()\n",
    "imshow(anatomical.as_array()[64, :, :])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "imshow(full_acquired_data.as_array()[0, 64, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from first MAPEM notebook\n",
    "\n",
    "The following chunk of code is copied and pasted more-or-less directly from the other notebook as a starting point. \n",
    "\n",
    "First, run the code chunk to get the objective functions etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construction of Likelihood objective functions and OSEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_fun(acquired_data, atten):\n",
    "    print('\\n------------- Setting up objective function')\n",
    "    #     #%% create objective function\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(atten, am)\n",
    "    asm_attn.set_up(acquired_data)\n",
    "    bin_eff = pet.AcquisitionData(acquired_data)\n",
    "    bin_eff.fill(1.0)\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    # Set sensitivity of the model and set up\n",
    "    am.set_acquisition_sensitivity(asm_attn)\n",
    "    am.set_up(acquired_data,atten);\n",
    "\n",
    "    #%% create objective function\n",
    "    obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
    "    obj_fun.set_acquisition_model(am)\n",
    "\n",
    "    print('\\n------------- Finished setting up objective function')\n",
    "    return obj_fun\n",
    "\n",
    "def get_reconstructor(num_subsets, num_subiters, obj_fun, init_image):\n",
    "    print('\\n------------- Setting up reconstructor') \n",
    "\n",
    "    #%% create OSEM reconstructor\n",
    "    OSEM_reconstructor = pet.OSMAPOSLReconstructor()\n",
    "    OSEM_reconstructor.set_objective_function(obj_fun)\n",
    "    OSEM_reconstructor.set_num_subsets(num_subsets)\n",
    "    OSEM_reconstructor.set_num_subiterations(num_subiters)\n",
    "\n",
    "    #%% initialise\n",
    "    OSEM_reconstructor.set_up(init_image)\n",
    "\n",
    "    print('\\n------------- Finished setting up reconstructor')\n",
    "    return OSEM_reconstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rebin to create a smaller sinogram to speed up calculations\n",
    "acquired_data = full_acquired_data.clone()\n",
    "acquired_data = acquired_data.rebin(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the objective function\n",
    "obj_fun = get_obj_fun(acquired_data, atten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement de Pierro MAP-EM for a quadratic prior with arbitrary weights\n",
    "The following code is almost a copy-paste of the implementation by A. Mehranian and S. Ellis [contributed during one of our hackathons](https://github.com/SyneRBI/SIRF-Contribs/tree/master/src/Python/sirf/contrib/kcl). It is copied here for you to have an easier look.\n",
    "\n",
    "Note that the code avoids the `for` loops in our simplistic version above and hence should be faster (however, the construction of the neighbourhood is still slow, but you should have to do this only once). Also, this is a Python reimplementation of MATLAB code (hence the use of \"Fortran order\" below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePierroReg(image,weights,nhoodIndVec):\n",
    "    \"\"\"Get the de Pierro regularisation image (xreg)\"\"\"\n",
    "    imSize = image.shape\n",
    "\n",
    "    # vectorise image for indexing \n",
    "    imageVec = image.reshape(-1,order='F')\n",
    "\n",
    "    # retrieve voxel intensities for neighbourhoods \n",
    "    resultVec = imageVec[nhoodIndVec]\n",
    "    result = resultVec.reshape(weights.shape,order='F')\n",
    "\n",
    "    # compute xreg\n",
    "    imageReg = 0.5*numpy.sum(weights*(result + image.reshape(-1,1,order='F')),axis=1)/numpy.sum(weights,axis=1)\n",
    "    imageReg = imageReg.reshape(imSize,order='F')\n",
    "\n",
    "    return imageReg\n",
    "\n",
    "def compute_nhoodIndVec(imageSize,weightsSize):\n",
    "    \"\"\"Get the neigbourhoods of each voxel\"\"\"\n",
    "    w = int(round(weightsSize[1]**(1.0/3))) # side length of neighbourhood\n",
    "    nhoodInd    = neighbourExtract(imageSize,w)\n",
    "    return nhoodInd.reshape(-1,order='F')\n",
    "\n",
    "def neighbourExtract(imageSize,w):\n",
    "    \"\"\"Adapted from kcl.Prior class\"\"\"\n",
    "    n = imageSize[0]\n",
    "    m = imageSize[1]\n",
    "    h = imageSize[2]\n",
    "    wlen = 2*numpy.floor(w/2)\n",
    "    widx = xidx = yidx = numpy.arange(-wlen/2,wlen/2+1)\n",
    "\n",
    "    if h==1:\n",
    "        zidx = [0]\n",
    "        nN = w*w\n",
    "    else:\n",
    "        zidx = widx\n",
    "        nN = w*w*w\n",
    "\n",
    "    Y,X,Z = numpy.meshgrid(numpy.arange(0,m), numpy.arange(0,n), numpy.arange(0,h))                \n",
    "    N = numpy.zeros([n*m*h, nN],dtype='int32')\n",
    "    l = 0\n",
    "    for x in xidx:\n",
    "        Xnew = setBoundary(X + x,n)\n",
    "        for y in yidx:\n",
    "            Ynew = setBoundary(Y + y,m)\n",
    "            for z in zidx:\n",
    "                Znew = setBoundary(Z + z,h)\n",
    "                N[:,l] = ((Xnew + (Ynew)*n + (Znew)*n*m)).reshape(-1,1).flatten('F')\n",
    "                l += 1\n",
    "    return N\n",
    "\n",
    "def setBoundary(X,n):\n",
    "    \"\"\"Boundary conditions for neighbourExtract.\n",
    "    Adapted from kcl.Prior class\"\"\"\n",
    "    idx = X<0\n",
    "    X[idx] = X[idx] + n\n",
    "    idx = X>n-1\n",
    "    X[idx] = X[idx] - n\n",
    "    return X.flatten('F')\n",
    "\n",
    "@jit\n",
    "def dePierroUpdate(xEM, imageReg, beta):\n",
    "    \"\"\"Update the image based on the de Pierro regularisation image\"\"\"\n",
    "    return (2*xEM)/(((1 - beta*imageReg)**2 + 4*beta*xEM)**0.5 + (1 - beta*imageReg) + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPEM_iteration(OSEM_reconstructor,current_image,weights,nhoodIndVec,beta):\n",
    "    image_reg = dePierroReg(current_image.as_array(),weights,nhoodIndVec) # compute xreg\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    updated = dePierroUpdate(image_EM, image_reg, beta) # compute new uxpdate\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    return current_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create uniform and Bowsher weights\n",
    "We will use the `kcl.Prior` class here to construct the Bowsher weights given an anatomical image. The `kcl.Prior` class (and the above code) assumes that the `weights` are returned an $N_v \\times N_n$ array, with $N_v$ the number of voxels and $N_n$ the number of neighbours (here 27 as the implementation is in 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.contrib.kcl.Prior as pr\n",
    "def update_bowsher_weights(prior,side_image,num_bowsher_neighbours):\n",
    "    return prior.BowshserWeights\\\n",
    "        (side_image.as_array(),num_bowsher_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we will keep only a few neighbours in the Bowsher prior. This makes the contrast with \"uniform\" weights higher of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bowsher_neighbours = 3\n",
    "myPrior = pr.Prior(anatomical_arr.shape)\n",
    "BowsherWeights = update_bowsher_weights(myPrior,anatomical,num_bowsher_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warning about `divide by zero`, it is actually handled in the `kcl.Prior` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of the neighbourhood for each voxel\n",
    "nhoodIndVec=compute_nhoodIndVec(anatomical_arr.shape,BowsherWeights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate that only a few of the weights in the neighbourhood are kept\n",
    "# (taking an arbitrary voxel)\n",
    "print(BowsherWeights[500,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could try to understand the neighbourhood structure using the following, but it is quite complicated due to the Fortran order and linear indices.\n",
    "```\n",
    "toLinearIndices=nhoodIndVec.reshape(BowsherWeights.shape,order='F')\n",
    "print(toLinearIndices[500,:])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use uniform weights where every neighbour is counted the same (often people will use 1/distance between voxels as weighting, but this isn't implemented here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformWeights=BowsherWeights.copy()\n",
    "uniformWeights[:,:]=1\n",
    "# set \"self-weight\" of the voxel to zero\n",
    "uniformWeights[:,27//2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uniformWeights[500,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets = 21\n",
    "num_subiters = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a normal OSEM (for comparison and initialisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do initial OSEM recon\n",
    "OSEM_reconstructor = get_reconstructor(num_subsets, num_subiters, obj_fun, init_image)\n",
    "osem_image = init_image.clone()\n",
    "OSEM_reconstructor.reconstruct(osem_image)\n",
    "\n",
    "plt.figure()\n",
    "imshow(osem_image.as_array()[60,:,:])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MAP-EM with the 2 different sets of weights\n",
    "To save some time, we will initialise the algorithms with the OSEM image. This makes sense of course as in the initial iterations, the penalty will just slow everything down (as it smooths an already too smooth image even more!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary value for the weight of the penalty. You might have to tune it\n",
    "beta=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute with Bowsher penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image=osem_image.clone()\n",
    "\n",
    "for it in trange(1, num_subiters+1):\n",
    "    current_image = MAPEM_iteration(OSEM_reconstructor,current_image,BowsherWeights,nhoodIndVec,beta)\n",
    "Bowsher=current_image.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute with uniform weights (we'll call the result UQP for \"uniform quadratic penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image=osem_image.clone()\n",
    "\n",
    "for it in trange(1, num_subiters+1):\n",
    "    current_image = MAPEM_iteration(OSEM_reconstructor,current_image,uniformWeights,nhoodIndVec,beta)\n",
    "\n",
    "UQP=current_image.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the anatomical, OSEM, and two MAPEM images\n",
    "plt.figure()\n",
    "cmax=osem_image.max()*.6\n",
    "clim=[0,cmax]\n",
    "subplot_([1,2,1],anatomical.as_array()[60,:,:],\"anatomical\")\n",
    "subplot_([1,2,2],osem_image.as_array()[60,:,:],\"OSEM\",clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "subplot_([1,2,1],UQP.as_array()[60,:,:],\"Uniform Quadratic prior\",clim)\n",
    "subplot_([1,2,2],Bowsher.as_array()[60,:,:],\"Bowsher Quadratic prior\",clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y_idx=osem_image.dimensions()[1]//2\n",
    "plt.plot(osem_image.as_array()[60,y_idx,:],label=\"OSEM\")\n",
    "plt.plot(UQP.as_array()[60,y_idx,:],label=\"Uniform Quadratic prior\")\n",
    "plt.plot(Bowsher.as_array()[60,y_idx,:],label=\"Bowsher Quadratic prior\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably see that the MAP-EM are quite smooth, and that there is very little difference between the \"uniform\" and \"Bowsher\" weights after this number of updates. The difference will get larger with higher number of updates (try it!).\n",
    "\n",
    "Also, with the Bowsher weights you should be able to increase `beta` more than for the uniform weights without oversmoothing the image too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misalignment between anatomical and emission images\n",
    "\n",
    "What happens if you want to use an anatomical prior but the image isn't aligned with the image you're trying to reconstruct?  \n",
    "\n",
    "You'll have to register them of course! Have a look at the [registration notebook](../Reg/sirf_registration.ipynb) if you haven't already.  \n",
    "\n",
    "The idea here would be to run an initial reconstruction (say, OSEM), and then register the anatomical image to the resulting reconstruction...\n",
    "\n",
    "Once we've got the anatomical image in the correct space, we can calculate the Bowsher weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.Reg as Reg\n",
    "\n",
    "registration = Reg.NiftyAladinSym()\n",
    "registration.set_reference_image\n",
    "registration.set_reference_image(osem_image)\n",
    "registration.set_floating_image(anatomical)\n",
    "registration.set_parameter('SetPerformRigid','1')\n",
    "registration.set_parameter('SetPerformAffine','0')\n",
    "registration.process()\n",
    "anatomical_in_emission_space = registration.get_output()\n",
    "\n",
    "Bweights = update_bowsher_weights(myPrior,anatomical_in_emission_space,num_bowsher_neighbours)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
