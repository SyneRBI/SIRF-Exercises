{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data based on BrainWeb images\n",
    "\n",
    "This notebook contains most of the lines from the [BrainWeb notebook](BrainWeb.ipynb). Here, the images are cropped to a single slice, and only the motion case is considered. It could serve as inspiration for you on how to speed things up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Richard Brown, Casper da Costa-Luis  \n",
    "First version: 2nd of November 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('Synergistic', 'BrainWeb_single_slice')\n",
    "\n",
    "import os\n",
    "import brainweb\n",
    "from brainweb import volshow\n",
    "import numpy as np\n",
    "from os import path\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import nibabel as nib\n",
    "import sirf.STIR as pet\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sirf.Reg as reg\n",
    "from math import cos, sin, pi, radians\n",
    "from sirf.Utilities import examples_data_path\n",
    "from sirf_exercises import exercises_data_path\n",
    "import shutil\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get brainweb data (just single patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, url= sorted(brainweb.utils.LINKS.items())[0]\n",
    "files = brainweb.get_file(fname, url, \".\")\n",
    "data = brainweb.load_file(fname)\n",
    "\n",
    "brainweb.seed(1337)\n",
    "\n",
    "for f in tqdm([fname], desc=\"mMR ground truths\", unit=\"subject\"):\n",
    "    vol = brainweb.get_mmr_fromfile(\n",
    "        f,\n",
    "        petNoise=1, t1Noise=0.75, t2Noise=0.75,\n",
    "        petSigma=1, t1Sigma=1, t2Sigma=1)\n",
    "    vol_amyl = brainweb.get_mmr_fromfile(\n",
    "        f,\n",
    "        petNoise=1, t1Noise=0.75, t2Noise=0.75,\n",
    "        petSigma=1, t1Sigma=1, t2Sigma=1,\n",
    "        PetClass=brainweb.Amyloid)\n",
    "\n",
    "FDG_arr  = vol['PET']\n",
    "amyl_arr = vol_amyl['PET']\n",
    "uMap_arr = vol['uMap']\n",
    "T1_arr   = vol['T1']\n",
    "T2_arr   = vol['T2']\n",
    "\n",
    "# Take centre slice to make 2d\n",
    "slice = FDG_arr.shape[0]//2\n",
    "FDG_arr  = FDG_arr[slice,:,:]\n",
    "amyl_arr = amyl_arr[slice,:,:]\n",
    "uMap_arr = uMap_arr[slice,:,:]\n",
    "T1_arr   = T1_arr[slice,:,:]\n",
    "T2_arr   = T2_arr[slice,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure();\n",
    "\n",
    "subplot_([2,3,1],FDG_arr [100:-100, 100:-100],'FDG'    ,cmap=\"hot\")\n",
    "subplot_([2,3,2],amyl_arr[100:-100, 100:-100],'Amyloid',cmap=\"hot\")\n",
    "subplot_([2,3,3],uMap_arr[100:-100, 100:-100],'uMap'   ,cmap=\"bone\")\n",
    "subplot_([2,3,4],T1_arr  [100:-100, 100:-100],'T1'     ,cmap=\"Greys_r\")\n",
    "subplot_([2,3,5],T2_arr  [100:-100, 100:-100],'T2'     ,cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images and save\n",
    "\n",
    "Here's what's going on in this cell:\n",
    "\n",
    "1. The data from brainweb is (127,344,344), but we want it to be (1,150,150). We've already cropped in the z-direction to (1,344,344). For x-y, just keep the middle sections of the image in the x-y plane.\n",
    "2. Crop the image to reduce it to (1,150,150).\n",
    "3. Save the image to file, both interfile and nifti\n",
    "\n",
    "N.B.: This requires you to have a version of SIRF > v2.1.0. See the cell at the bottom of this notebook if you have an older version of SIRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need a template sinogram\n",
    "mmr_template_sino_single_slice = examples_data_path('PET') + '/mMR/mMR_template_single_slice.hs'\n",
    "templ_sino = pet.AcquisitionData(mmr_template_sino_single_slice)\n",
    "\n",
    "def crop_and_save(templ_sino, im_array, fname):\n",
    "    # Crop from (1,344,344) to (1,150,150) and save to file\n",
    "    im_array = im_array[97:97+150,97:97+150]\n",
    "    im_array = np.expand_dims(im_array, axis = 0)\n",
    "    im = pet.ImageData(templ_sino)\n",
    "    dim=(1,150,150)\n",
    "    voxel_size=im.voxel_sizes()\n",
    "    im.initialise(dim,voxel_size)\n",
    "    im.fill(im_array)\n",
    "    im.write(fname)\n",
    "    im_nii = reg.ImageData(im)\n",
    "    im_nii.write(fname)\n",
    "    return im\n",
    "    \n",
    "FDG  = crop_and_save(templ_sino, FDG_arr,  \"FDG\"    )\n",
    "amyl = crop_and_save(templ_sino, amyl_arr, \"Amyloid\")\n",
    "uMap = crop_and_save(templ_sino, uMap_arr, \"uMap\"   )\n",
    "T1   = crop_and_save(templ_sino, T1_arr,   \"T1\"     )\n",
    "T2   = crop_and_save(templ_sino, T2_arr,   \"T2\"     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "subplot_([2,3,1],np.squeeze(FDG.as_array()),  'FDG'    ,cmap=\"hot\")\n",
    "subplot_([2,3,2],np.squeeze(amyl.as_array()), 'Amyloid',cmap=\"hot\")\n",
    "subplot_([2,3,3],np.squeeze(uMap.as_array()), 'uMap'   ,cmap=\"bone\")\n",
    "subplot_([2,3,4],np.squeeze(T1.as_array()),   'T1'     ,cmap=\"Greys_r\")\n",
    "subplot_([2,3,5],np.squeeze(T2.as_array()),   'T2'     ,cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add motion\n",
    "\n",
    "Resample the image using SIRF's wrapper around NiftyReg. \n",
    "\n",
    "As with the crop, moving an image around affects its offset in STIR, which currently causes problems. So again, we recentre the image after the resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_misalignment(transformation_matrix,image):\n",
    "\n",
    "    # Resample\n",
    "    resampler = reg.NiftyResample()\n",
    "    resampler.set_interpolation_type_to_cubic_spline()\n",
    "    resampler.set_reference_image(image)\n",
    "    resampler.set_floating_image(image)\n",
    "    resampler.set_padding_value(0)\n",
    "    resampler.add_transformation(transformation_matrix)\n",
    "    resampler.process()\n",
    "\n",
    "    # Save to file\n",
    "    resampled = resampler.get_output()\n",
    "\n",
    "    # Remove all offset info (avoids problems in STIR)\n",
    "    misaligned_image = resampled.move_to_scanner_centre(templ_sino)\n",
    "    return misaligned_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the transformation matrix\n",
    "\n",
    "The rotation matrix we'll use here is a rotation of 30 degrees about one of the axes, and a translation of 20 and -10 mm in the x- and y-directions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ims = [FDG, amyl, uMap, T1, T2]\n",
    "FDGs = []\n",
    "amyls = []\n",
    "uMaps = []\n",
    "T1s = []\n",
    "T2s = []\n",
    "num_motion_states = 4\n",
    "for i in range(num_motion_states):\n",
    "    \n",
    "    # Get some motion\n",
    "    if i == 0:\n",
    "        [r,t_x,t_y] = [0., 0., 0.]\n",
    "    elif i == 1: \n",
    "        [r,t_x,t_y] = [10., -10., 0.]\n",
    "    elif i == 2: \n",
    "        [r,t_x,t_y] = [20., -5., 5.]\n",
    "    elif i == 3: \n",
    "        [r,t_x,t_y] = [-10., 10., 5.]\n",
    "    else:\n",
    "        raise AssertionError('need more motion')\n",
    "        \n",
    "    r = radians(r)\n",
    "    tm = reg.AffineTransformation(np.array(\\\n",
    "        [[ cos(r), sin(r), 0, t_x], \\\n",
    "         [-sin(r), cos(r), 0, t_y], \\\n",
    "         [      0,      0, 1, 0  ], \\\n",
    "         [      0,      0, 0, 1  ]]))\n",
    "    \n",
    "    # Apply motion to all FDG, uMap, T1, etc.\n",
    "    resampled_ims = []\n",
    "    for j in range(len(input_ims)):\n",
    "        im = input_ims[j]\n",
    "        # Resample\n",
    "        resampler = reg.NiftyResample()\n",
    "        resampler.set_interpolation_type_to_cubic_spline()\n",
    "        resampler.set_reference_image(im)\n",
    "        resampler.set_floating_image(im)\n",
    "        resampler.set_padding_value(0)\n",
    "        resampler.add_transformation(tm)\n",
    "        resampled = resampler.forward(im)\n",
    "        resampled.move_to_scanner_centre(templ_sino)\n",
    "        \n",
    "        if j==0:\n",
    "            fname = 'FDG'\n",
    "            FDGs.append(resampled)\n",
    "        elif j==1:\n",
    "            fname = 'amyl'\n",
    "            amyls.append(resampled)\n",
    "        elif j==2:\n",
    "            fname = 'uMap'\n",
    "            uMaps.append(resampled)\n",
    "        elif j==3:\n",
    "            fname = 'T1'\n",
    "            T1s.append(resampled)\n",
    "        elif j==4:\n",
    "            fname = 'T2'\n",
    "            T2s.append(resampled)\n",
    "            \n",
    "        reg.ImageData(resampled).write(fname + '_mf' + str(i))\n",
    "        tm.write('fwd_tm_mf' + str(i))\n",
    "        tm.get_inverse().write('inv_tm_mf' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "plt.figure();\n",
    "for i in range(num_motion_states):\n",
    "    subplot_([2,2,i+1], np.squeeze(FDGs[i].as_array()), 'Motion state ' + str(i), clims=[0, 160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward project\n",
    "\n",
    "Forward project both the FDG and amyloid images both with and without Poisson noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acquisition_model(uMap, templ_sino):\n",
    "\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(uMap, am)\n",
    "    asm_attn.set_up(templ_sino)\n",
    "    bin_eff = pet.AcquisitionData(templ_sino)\n",
    "    bin_eff.fill(1.0)\n",
    "    print('applying attenuation (please wait, may take a while)...')\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    am.set_acquisition_sensitivity(asm_attn)\n",
    "\n",
    "    am.set_up(templ_sino,uMap);\n",
    "    return am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding noise\n",
    "def add_noise(proj_data,noise_factor = 1):\n",
    "    proj_data_arr = proj_data.as_array() / noise_factor\n",
    "    # Data should be >=0 anyway, but add abs just to be safe\n",
    "    proj_data_arr = np.abs(proj_data_arr)\n",
    "    noisy_proj_data_arr = np.random.poisson(proj_data_arr).astype('float32');\n",
    "    noisy_proj_data = proj_data.clone()\n",
    "    noisy_proj_data.fill(noisy_proj_data_arr);\n",
    "    return noisy_proj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDG_sinos = []\n",
    "FDG_sinos_noisy = []\n",
    "\n",
    "for i in range(num_motion_states):\n",
    "    am = get_acquisition_model(uMaps[i], templ_sino)\n",
    "    FDG_sino = am.forward(FDGs[i])\n",
    "    noisy_FDG_sino = add_noise(FDG_sino,1000)\n",
    "    FDG_sino.write('sino_FDG_mf' + str(i))\n",
    "    noisy_FDG_sino.write('sino_FDG_noisy_mf' + str(i))\n",
    "    FDG_sinos.append(FDG_sino)\n",
    "    FDG_sinos_noisy.append(noisy_FDG_sino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDG_sinos[i].as_array().shape\n",
    "plt.figure();\n",
    "for i in range(num_motion_states):\n",
    "    subplot_([num_motion_states,2,i*2+1],   FDG_sinos[i].as_array()[0,0,:,:], 'FDG sino, mf' + str(i))\n",
    "    subplot_([num_motion_states,2,i*2+2], FDG_sinos_noisy[i].as_array()[0,0,:,:], 'FDG sino (noisy), mf' + str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
