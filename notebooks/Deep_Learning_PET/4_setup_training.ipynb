{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a training loop with validation.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "\n",
    "Author: Imraj Singh\n",
    "\n",
    "First version: 13th of May 2022\n",
    "\n",
    "CCP SyneRBI Synergistic Image Reconstruction Framework (SIRF).\n",
    "Copyright 2022 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational Project in Synergistic Reconstruction for Biomedical Imaging (http://www.ccpsynerbi.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "# Setting up the training\n",
    "\n",
    "This is very standard pytorch parlance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideas:\n",
    "* Setup acquisition model\n",
    "* Setup dataset\n",
    "* Setup model\n",
    "* Setup training loop with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PET reconstruction engine\n",
    "import sirf.STIR as pet\n",
    "# Set the verbosity\n",
    "pet.set_verbosity(0)\n",
    "# Store tempory sinograms in RAM\n",
    "pet.AcquisitionData.set_storage_scheme(\"memory\")\n",
    "# SIRF STIR message redirector\n",
    "import sirf\n",
    "msg = sirf.STIR.MessageRedirector(info=None, warn=None, errr=None)\n",
    "# Load dataset and model\n",
    "from odl_funcs.ellipses import EllipsesDataset\n",
    "from lpd_net import LearnedPrimalDual\n",
    "# Import standard extra packages\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "size_xy = 128\n",
    "batch = 10\n",
    "from sirf.Utilities import examples_data_path\n",
    "sinogram_template = pet.AcquisitionData(examples_data_path('PET')\\\n",
    "                                        + '/thorax_single_slice/template_sinogram.hs');\n",
    "# create acquisition model\n",
    "acq_model = pet.AcquisitionModelUsingParallelproj();\n",
    "image_template = sinogram_template.create_uniform_image(1.0,size_xy);\n",
    "acq_model.set_up(sinogram_template,image_template);\n",
    "train_dataloader = torch.utils.data.DataLoader( \\\n",
    "    EllipsesDataset(acq_model.forward, image_template, mode=\"train\", n_samples = 50) \\\n",
    "    , batch_size=batch, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader( \\\n",
    "    EllipsesDataset(acq_model.forward, image_template, mode=\"valid\") \\\n",
    "    , batch_size=1, shuffle=True)\n",
    "model = LearnedPrimalDual(image_template, sinogram_template,\\\n",
    "                          acq_model, n_iter = 5, n_primal = 5, n_dual = 5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the training loop with validation and a very simply \"data logger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "total_epochs = 500\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.99, 0.999))\n",
    "\n",
    "data_log = {}\n",
    "data_log[\"valid_loss\"] = []\n",
    "data_log[\"valid_image\"] = []\n",
    "data_log[\"loss\"] = []\n",
    "\n",
    "min_valid_loss = 1e9\n",
    "\n",
    "x_gt_valid, y_valid = next(iter(valid_dataloader))\n",
    "x_gt_valid, y_valid = x_gt_valid.float().to(device), y_valid.float().to(device)\n",
    "model.load_state_dict(torch.load('quasi_trained_model.torch_model'))\n",
    "pbar1 = trange(total_epochs, position=0, leave=True, desc='Epochs')\n",
    "pbar2 = tqdm(train_dataloader, position=1, leave=True, desc='Iterations')\n",
    "for i in pbar1:\n",
    "    model.eval()\n",
    "    x_valid = model(y_valid);\n",
    "    loss_valid = criterion(x_gt_valid, x_valid)\n",
    "    pbar1.set_description(\"Epoch, loss {:10.2f}\".format(loss_valid.item()))\n",
    "    data_log[\"valid_loss\"].append(loss_valid.item())\n",
    "    data_log[\"valid_image\"].append(x_valid[0,0,...].detach().cpu().numpy())\n",
    "    if min_valid_loss > loss_valid.item():\n",
    "        best_model = model.state_dict()\n",
    "    pbar2.reset(5)\n",
    "    for ii, (x_gt, y) in enumerate(train_dataloader):\n",
    "        x_gt, y = x_gt.float().to(device), y.float().to(device)\n",
    "        model.train();\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        x = model(y);\n",
    "        # Compute and print loss\n",
    "        loss = criterion(x_gt, x)\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        data_log[\"loss\"].append(loss.item())\n",
    "        pbar2.update()\n",
    "        pbar2.set_description(\"Batch sample, loss {:10.2f}\".format(loss.item()))\n",
    "    \n",
    "torch.save(best_model, 'quasi_trained_model.torch_model')\n",
    "np.save('results',data_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look as some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.load('results.npy',allow_pickle=True).item()\n",
    "#plt.plot(r['loss'])\n",
    "#plt.plot(np.log(r['valid_loss']))\n",
    "\n",
    "min_loss = np.argmin(r['valid_loss'])\n",
    "print(min_loss)\n",
    "print(r['valid_loss'][min_loss])\n",
    "plt.imshow(r['valid_image'][min_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "* Do inference of BrainWeb data (i.e. add a test set)\n",
    "* See the reconstruction at various points in the network\n",
    "* Compare with OSEM reconstruction\n",
    "* Attempt to improve the model (change training parameters?)\n",
    "* Use \"realistic\" acquisition model for training data generation, but \"simple\" acquisition model for reconstruction\n",
    "* Add more physics to the forward model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "cee20aa2885cadc07e824ce5082d40bca942426616eda434cad5578791d33ff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
