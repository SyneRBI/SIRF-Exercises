{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECT Oredered Subsets Expectation Maximisation Notebook\n",
    "A notebook to demonstrate the setup and basic OSEM reconstrcution of a 2-dimensional dummy image using SIRF's SPECT projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # What is OSEM?\n",
    "The following is just a very brief explanation of the concepts behind OSEM.\n",
    "\n",
    "PET reconstruction is commonly based on the *Maximum Likelihood Estimation (MLE)* principle. The *likelihood* is the probability to observe some measured data given a (known) image. MLE attempts to find the image that maximises this likelihood. This needs to be done iteratively as the system of equations is very non-linear.\n",
    "\n",
    "A common iterative method uses *Expectation Maximisation*, which we will not explain here. The resulting algorithm is called *MLEM* (or sometimes *EMML*). However, it is rather slow. The most popular method to increase computation speed is to compute every image update based on only a subset of the data. Subsets are nearly always chosen in terms of the \"views\" (or azimuthal angles). The *Ordered Subsets Expectation Maximisation (OSEM)* cycles through the subsets. More on this in another notebook, but here we just show how to use the SIRF implementation of OSEM.\n",
    "\n",
    "OSEM is (still) the most common algorithm in use in clinical PET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a skeleton for a simple OSEM reconstruction using the SIRF SPECT projector and OSEM reconstructor.\n",
    "See the **PET_OSEM** and **SPECT_Acquisition** model notebooks for information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import notebook_setup\n",
    "\n",
    "from sirf.STIR import show_2D_array\n",
    "import sirf.STIR as spect\n",
    "from sirf.Utilities import examples_data_path\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "data_path = examples_data_path('SPECT')\n",
    "\n",
    "cd_to_working_dir(\"SPECT\", \"OSEM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redirect information, warning and error messages to log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_red = spect.MessageRedirector('info.txt', 'warn.txt', 'errr.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_image(image):\n",
    "    '''fill the image with some simple geometric shapes.'''\n",
    "    image.fill(0)\n",
    "    # create a shape\n",
    "    shape = spect.EllipticCylinder()\n",
    "    shape.set_length(400)\n",
    "    shape.set_radii((100, 40))\n",
    "    shape.set_origin((0, 60, 10))\n",
    "\n",
    "    # add the shape to the image\n",
    "    image.add_shape(shape, scale = 1)\n",
    "\n",
    "    # add another shape\n",
    "    shape.set_radii((30, 30))\n",
    "    shape.set_origin((60, -30, 10))\n",
    "    shape.set_origin((60, -30, 10))\n",
    "    image.add_shape(shape, scale = 1.5)\n",
    "\n",
    "    # add another shape\n",
    "    shape.set_origin((-60, -30, 10))\n",
    "    image.add_shape(shape, scale = 0.75)\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV.\"\"\"\n",
    "    cyl_filter =spect.TruncateToCylinderProcessor()\n",
    "    cyl_filter.apply(image)\n",
    "    return image\n",
    "\n",
    "def add_noise(proj_data,noise_factor = 1):\n",
    "    \"\"\"Add Poission noise to acquisition data.\"\"\"\n",
    "    proj_data_arr = proj_data.as_array() / noise_factor\n",
    "    # Data should be >=0 anyway, but add abs just to be safe\n",
    "    proj_data_arr = np.abs(proj_data_arr)\n",
    "    noisy_proj_data_arr = np.random.poisson(proj_data_arr).astype('float32');\n",
    "    noisy_proj_data = proj_data.clone()\n",
    "    noisy_proj_data.fill(noisy_proj_data_arr);\n",
    "    return noisy_proj_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ground truth and simulated data images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a template acquisition data object from file. I'll do this for you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templ_sino = spect.AcquisitionData(os.path.join(data_path,'template_sinogram.hs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this template sinogram to create a simple ground truth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ground truth image\n",
    "image = templ_sino.create_uniform_image()\n",
    "create_sample_image(image)\n",
    "image = image.zoom_image(zooms=(0.5, 1.0, 1.0)) #required for now because SPECT is 360 degree acquisiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the ground truth image\n",
    "image_array = image.as_array()\n",
    "show_2D_array('Phantom image', image_array[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the acquisition model by first creating an acquisition matrix (SPECTUBMatrix) object and apply this to a sirf Acquisition Model (AcquisitionModelUsingMatrix) object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Acquisition Model code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, forward project our ground truth image and add noise to simulate noisy acquired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('projecting image...')\n",
    "# project the image to obtain simulated acquisition data\n",
    "# data from raw_data_file is used as a template\n",
    "acq_model.set_up(templ_sino, image)\n",
    "simulated_data = templ_sino.get_uniform_copy()\n",
    "acq_model.forward(image, 0, 1, simulated_data)\n",
    "\n",
    "# create noisy data\n",
    "noisy_data = simulated_data.clone()\n",
    "noisy_data_as_array = np.random.poisson(simulated_data.as_array())\n",
    "noisy_data.fill(noisy_data_as_array)\n",
    "\n",
    "# show simulated acquisition data\n",
    "simulated_data_as_array = simulated_data.as_array()\n",
    "show_2D_array('Forward projection', simulated_data_as_array[0, 0,:,:])\n",
    "show_2D_array('Forward projection with added noise', noisy_data_as_array[0, 0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the reconstruction problem's objective function and use this to create an OSEM reconstructor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Objective Function code here ###\n",
    "\n",
    "num_subsets = 21 # number of subsets for OSEM reconstruction\n",
    "num_subiters = 42 #number of subiterations (i.e two full iterations)\n",
    "\n",
    "### OSEM reconstructor code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initialisation image and set up reconstructor\n",
    "init_image = make_cylindrical_FOV(image.get_uniform_copy(1))\n",
    "\n",
    "### Now set_up the reconstructor object using the initial image ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the reconstruction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reconstruction code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_2D_array('Reconstructed image', np.squeeze(out.as_array()[0,:,:])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% delete temporary files\n",
    "wdpath = os.getcwd()\n",
    "for filename in glob.glob(os.path.join(wdpath, \"tmp*\")):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: reconstruct with and without attenuation and resolution modelling\n",
    "* Investigate the effect of resolution modelling and attenuation on the reconstructed image\n",
    "* What happens if you have a different resolution model for the simulated data and the reconstrcution?\n",
    "\n",
    "Hint: help(spect.SPECTUBMatrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
