{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4c8051",
   "metadata": {},
   "source": [
    "Sinogram and Listmode OSEM using sirf.STIR\n",
    "==========================================\n",
    "\n",
    "Using the learnings from the previous \"theory\" notebook, we will now learn how to perform\n",
    "PET reconstruction of emission data in listmode and sinogram format using (sinogram and listmode)\n",
    "objective function objects of the sirf.STIR library.\n",
    "\n",
    "We will see that standard OSEM reconstruction can be seen as a sequence of image update \"blocks\",\n",
    "where the update in each block is related to the gradient of the Poisson loglikelihood objective function.\n",
    "\n",
    "Understanding these OSEM update blocks is the first key step for implementing a pytorch-based feed-forward\n",
    "neural network for PET image reconstruction also containing OSEM-like update blocks.\n",
    "\n",
    "Learning objectives of this notebook\n",
    "------------------------------------\n",
    "1. Understanding how to setup a Poisson loglikelihood objective functions in sinogram and listmode mode.\n",
    "2. Understanding how to perform sinogram / listmode OSEM reconstruction using sirf.STIR high-level API.\n",
    "3. Implementing a simple DIY OSEM reconstruction using the gradient of the Poisson loglikelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a673c6",
   "metadata": {},
   "source": [
    "Import modules\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.STIR\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sirf.Utilities import examples_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba36090",
   "metadata": {},
   "source": [
    "Download the 60min mMR NEMA data, if not present\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51069f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (\n",
    "    Path(\"..\")\n",
    "    / \"..\"\n",
    "    / \"data\"\n",
    "    / \"PET\"\n",
    "    / \"mMR\"\n",
    "    / \"NEMA_IQ\"\n",
    "    / \"20170809_NEMA_60min_UCL.l.hdr\"\n",
    ").exists():\n",
    "    retval = subprocess.call(\"../../scripts/download_PET_data.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8deef",
   "metadata": {},
   "source": [
    "Define variables and file names\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a 1min and 60min acquisition of the NEMA IQ phantom acquired on a Siemens mMR\n",
    "# choose the acquisition time \"1min\" or \"60min\" - start with \"1min\"\n",
    "acq_time: str = \"1min\"\n",
    "\n",
    "data_path: Path = Path(examples_data_path(\"PET\")) / \"mMR\"\n",
    "\n",
    "if acq_time == \"1min\":\n",
    "    list_file: str = str(data_path / \"list.l.hdr\")\n",
    "elif acq_time == \"60min\":\n",
    "    # you need to run the \"download_data.sh\" script to get the data of the long 60min acq.\n",
    "    list_file: str = str(\n",
    "        Path(\"..\")\n",
    "        / \"..\"\n",
    "        / \"data\"\n",
    "        / \"PET\"\n",
    "        / \"mMR\"\n",
    "        / \"NEMA_IQ\"\n",
    "        / \"20170809_NEMA_60min_UCL.l.hdr\"\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Please choose acq_time to be either '1min' or '60min'\")\n",
    "\n",
    "attn_file: str = str(data_path / \"mu_map.hv\")\n",
    "norm_file: str = str(data_path / \"norm.n.hdr\")\n",
    "output_path: Path = Path(f\"recons_{acq_time}\")\n",
    "emission_sinogram_output_prefix: str = str(output_path / \"emission_sinogram\")\n",
    "scatter_sinogram_output_prefix: str = str(output_path / \"scatter_sinogram\")\n",
    "randoms_sinogram_output_prefix: str = str(output_path / \"randoms_sinogram\")\n",
    "attenuation_sinogram_output_prefix: str = str(output_path / \"acf_sinogram\")\n",
    "recon_output_file: str = str(output_path / \"recon\")\n",
    "lm_recon_output_file: str = str(output_path / \"lm_recon\")\n",
    "nxny: tuple[int, int] = (127, 127)\n",
    "num_subsets: int = 21\n",
    "num_iter: int = 1\n",
    "num_scatter_iter: int = 3\n",
    "\n",
    "# create the output directory\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# engine's messages go to files, except error messages, which go to stdout\n",
    "_ = sirf.STIR.MessageRedirector(\"info.txt\", \"warn.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06174a26",
   "metadata": {},
   "source": [
    "Read the listmode data and create a sinogram template\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sirf.STIR.AcquisitionData.set_storage_scheme(\"memory\")\n",
    "listmode_data = sirf.STIR.ListmodeData(list_file)\n",
    "acq_data_template = listmode_data.acquisition_data_template()\n",
    "print(acq_data_template.get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd482ad",
   "metadata": {},
   "source": [
    "Conversion of listmode to sinogram data (needed for scatter estimation)\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33605685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create listmode-to-sinograms converter object\n",
    "lm2sino = sirf.STIR.ListmodeToSinograms()\n",
    "\n",
    "# set input, output and template files\n",
    "lm2sino.set_input(listmode_data)\n",
    "lm2sino.set_output_prefix(emission_sinogram_output_prefix)\n",
    "lm2sino.set_template(acq_data_template)\n",
    "\n",
    "# get the start and end time of the listmode data\n",
    "frame_start = float(\n",
    "    [\n",
    "        x\n",
    "        for x in listmode_data.get_info().split(\"\\n\")\n",
    "        if x.startswith(\"Time frame start\")\n",
    "    ][0]\n",
    "    .split(\": \")[1]\n",
    "    .split(\"-\")[0]\n",
    ")\n",
    "frame_end = float(\n",
    "    [\n",
    "        x\n",
    "        for x in listmode_data.get_info().split(\"\\n\")\n",
    "        if x.startswith(\"Time frame start\")\n",
    "    ][0]\n",
    "    .split(\": \")[1]\n",
    "    .split(\"-\")[1]\n",
    "    .split(\"(\")[0]\n",
    ")\n",
    "# set interval\n",
    "lm2sino.set_time_interval(frame_start, frame_end)\n",
    "# set up the converter\n",
    "lm2sino.set_up()\n",
    "\n",
    "# convert (need it for the scatter estimate)\n",
    "lm2sino.process()\n",
    "acq_data = lm2sino.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab46de",
   "metadata": {},
   "source": [
    "Estimation of random coincidences\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f9ae9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "randoms_filepath = Path(f\"{randoms_sinogram_output_prefix}.hs\")\n",
    "\n",
    "if not randoms_filepath.exists():\n",
    "    print(\"estimting randoms\")\n",
    "    randoms = lm2sino.estimate_randoms()\n",
    "    randoms.write(randoms_sinogram_output_prefix)\n",
    "else:\n",
    "    print(\"reading randoms from {randoms_filepath}\")\n",
    "    randoms = sirf.STIR.AcquisitionData(str(randoms_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d5385",
   "metadata": {},
   "source": [
    "Setup of the acquisition model\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ea4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select acquisition model that implements the geometric\n",
    "# forward projection by a ray tracing matrix multiplication\n",
    "acq_model = sirf.STIR.AcquisitionModelUsingRayTracingMatrix()\n",
    "# acq_model.set_num_tangential_LORs(10)\n",
    "acq_model.set_num_tangential_LORs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43a98f",
   "metadata": {},
   "source": [
    "Calculation of the attenuation sinogram\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read attenuation image and display a single slice\n",
    "attn_image = sirf.STIR.ImageData(attn_file)\n",
    "\n",
    "# create attenuation factors\n",
    "asm_attn = sirf.STIR.AcquisitionSensitivityModel(attn_image, acq_model)\n",
    "# converting attenuation image into attenuation factors (one for every bin)\n",
    "asm_attn.set_up(acq_data)\n",
    "\n",
    "acf_filepath = Path(f\"{attenuation_sinogram_output_prefix}.hs\")\n",
    "\n",
    "if not acf_filepath.exists():\n",
    "    ac_factors = acq_data.get_uniform_copy(value=1)\n",
    "    print(\"applying attenuation (please wait, may take a while)...\")\n",
    "    asm_attn.unnormalise(ac_factors)\n",
    "    ac_factors.write(attenuation_sinogram_output_prefix)\n",
    "else:\n",
    "    print(f\"reading attenuation factors from {acf_filepath}\")\n",
    "    ac_factors = sirf.STIR.AcquisitionData(str(acf_filepath))\n",
    "\n",
    "asm_attn = sirf.STIR.AcquisitionSensitivityModel(ac_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787d668",
   "metadata": {},
   "source": [
    "Creation of the normalization factors (sensitivity sinogram)\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create acquisition sensitivity model from normalisation data\n",
    "asm_norm = sirf.STIR.AcquisitionSensitivityModel(norm_file)\n",
    "\n",
    "asm = sirf.STIR.AcquisitionSensitivityModel(asm_norm, asm_attn)\n",
    "asm.set_up(acq_data)\n",
    "acq_model.set_acquisition_sensitivity(asm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e464da",
   "metadata": {},
   "source": [
    "Estimation of scattered coincidences\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_filepath: Path = Path(f\"{scatter_sinogram_output_prefix}_{num_scatter_iter}.hs\")\n",
    "\n",
    "if not scatter_filepath.exists():\n",
    "    print(\"estimating scatter (this will take a while!)\")\n",
    "    scatter_estimator = sirf.STIR.ScatterEstimator()\n",
    "    scatter_estimator.set_input(acq_data)\n",
    "    scatter_estimator.set_attenuation_image(attn_image)\n",
    "    scatter_estimator.set_randoms(randoms)\n",
    "    scatter_estimator.set_asm(asm_norm)\n",
    "    # invert attenuation factors to get the correction factors,\n",
    "    # as this is unfortunately what a ScatterEstimator needs\n",
    "    acf_factors = acq_data.get_uniform_copy()\n",
    "    acf_factors.fill(1 / ac_factors.as_array())\n",
    "    scatter_estimator.set_attenuation_correction_factors(acf_factors)\n",
    "    scatter_estimator.set_output_prefix(scatter_sinogram_output_prefix)\n",
    "    scatter_estimator.set_num_iterations(num_scatter_iter)\n",
    "    scatter_estimator.set_up()\n",
    "    scatter_estimator.process()\n",
    "    scatter_estimate = scatter_estimator.get_output()\n",
    "else:\n",
    "    print(f\"reading scatter from file {scatter_filepath}\")\n",
    "    scatter_estimate = sirf.STIR.AcquisitionData(str(scatter_filepath))\n",
    "\n",
    "# add scatter plus randoms estimated to the background term of the acquisition model\n",
    "acq_model.set_background_term(randoms + scatter_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbd779",
   "metadata": {},
   "source": [
    "Setup of the Poisson loglikelihood objective function in sinogram mode\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09272e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_image = acq_data.create_uniform_image(value=1, xy=nxny)\n",
    "\n",
    "# create objective function\n",
    "obj_fun = sirf.STIR.make_Poisson_loglikelihood(acq_data)\n",
    "obj_fun.set_acquisition_model(acq_model)\n",
    "obj_fun.set_num_subsets(num_subsets)\n",
    "obj_fun.set_up(initial_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd020f",
   "metadata": {},
   "source": [
    "Image reconstruction (optimization of the Poisson logL objective function) using sinogram OSEM\n",
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(f\"{recon_output_file}.hv\").exists():\n",
    "    reconstructor = sirf.STIR.OSMAPOSLReconstructor()\n",
    "    reconstructor.set_objective_function(obj_fun)\n",
    "    reconstructor.set_num_subsets(num_subsets)\n",
    "    reconstructor.set_num_subiterations(num_iter * num_subsets)\n",
    "    reconstructor.set_input(acq_data)\n",
    "    reconstructor.set_up(initial_image)\n",
    "    reconstructor.set_current_estimate(initial_image)\n",
    "    reconstructor.process()\n",
    "    ref_recon = reconstructor.get_output()\n",
    "    ref_recon.write(recon_output_file)\n",
    "else:\n",
    "    ref_recon = sirf.STIR.ImageData(f\"{recon_output_file}.hv\")\n",
    "\n",
    "vmax = np.percentile(ref_recon.as_array(), 99.999)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), tight_layout=True)\n",
    "ax.imshow(ref_recon.as_array()[71, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f00cd9",
   "metadata": {},
   "source": [
    "Exercise 1.1\n",
    "------------\n",
    "\n",
    "Perform the gradient ascent step\n",
    "$$ x^+ = x + \\alpha \\nabla_x logL(y,x) $$\n",
    "on the initial image x using a constant scalar step size $\\alpha=0.001$ by calling\n",
    "the `gradient()` method of the objective function.\n",
    "Use the first (0th) subset of the data for the gradient calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ==============\n",
    "# YOUR CODE HERE\n",
    "# ==============\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a503087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the solution, execute the this cell\n",
    "%load snippets/solution_1_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b333dc",
   "metadata": {},
   "source": [
    "Exercise 1.2\n",
    "------------\n",
    "\n",
    "Given the fact that the OSEM update can be written as\n",
    "$$ x^+ = x + t \\nabla_x logL(y,x) $$\n",
    "with the non-scalar step size\n",
    "$$ t = \\frac{x}{s} $$\n",
    "where $s$ is the (subset) \"sensitivity image\", perform an OSEM update on the initial image\n",
    "by using the `get_subset_sensitivity()` method of the objective function and the first subset.\n",
    "Print the maximum value of the updated image. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ==============\n",
    "# YOUR CODE HERE\n",
    "# ==============\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the solution, execute the this cell\n",
    "%load snippets/solution_1_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0591d",
   "metadata": {},
   "source": [
    "Exercise 1.3\n",
    "------------\n",
    "\n",
    "Implement your own OSEM reconstruction by looping over the subsets and performing the\n",
    "OSEM update for each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the reconstruction with ones where the sensitivity image is greater than 0\n",
    "# all other values are set to zero and are not updated during reconstruction\n",
    "recon = initial_image.copy()\n",
    "recon.fill(obj_fun.get_subset_sensitivity(0).as_array() > 0)\n",
    "#\n",
    "# ==============\n",
    "# YOUR CODE HERE\n",
    "# ==============\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf17ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# to view the solution, execute the this cell\n",
    "%load snippets/solution_1_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1b05f",
   "metadata": {},
   "source": [
    "Setup of the Poisson loglikelihood objective function logL(y,x) in listmode\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9115ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the listmode objective function\n",
    "lm_obj_fun = (\n",
    "    sirf.STIR.PoissonLogLikelihoodWithLinearModelForMeanAndListModeDataWithProjMatrixByBin()\n",
    ")\n",
    "lm_obj_fun.set_acquisition_model(acq_model)\n",
    "lm_obj_fun.set_acquisition_data(listmode_data)\n",
    "lm_obj_fun.set_num_subsets(num_subsets)\n",
    "lm_obj_fun.set_cache_max_size(1000000000)\n",
    "lm_obj_fun.set_cache_path(str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37459fa7",
   "metadata": {},
   "source": [
    "Reconstruction (optimization of the Poisson logL objective function) using listmode OSEM\n",
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(f\"{lm_recon_output_file}.hv\").exists():\n",
    "    lm_reconstructor = sirf.STIR.OSMAPOSLReconstructor()\n",
    "    lm_reconstructor.set_objective_function(lm_obj_fun)\n",
    "    lm_reconstructor.set_num_subsets(num_subsets)\n",
    "    lm_reconstructor.set_num_subiterations(num_iter * num_subsets)\n",
    "    lm_reconstructor.set_up(initial_image)\n",
    "    lm_reconstructor.set_current_estimate(initial_image)\n",
    "    lm_reconstructor.process()\n",
    "    lm_ref_recon = lm_reconstructor.get_output()\n",
    "    lm_ref_recon.write(lm_recon_output_file)\n",
    "else:\n",
    "    lm_ref_recon = sirf.STIR.ImageData(f\"{lm_recon_output_file}.hv\")\n",
    "\n",
    "fig3, ax3 = plt.subplots(1, 1, figsize=(4, 4), tight_layout=True)\n",
    "ax3.imshow(lm_ref_recon.as_array()[71, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd7bd3",
   "metadata": {},
   "source": [
    "Exercise 1.4\n",
    "------------\n",
    "Repeat exercise 1.3 (OSEM reconstruction) using the listmode objective function to\n",
    "learn how to do a listmode OSEM update step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ==============\n",
    "# YOUR CODE HERE\n",
    "# =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88dbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the solution, execute the cell below\n",
    "%load snippets/solution_1_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e75f8",
   "metadata": {},
   "source": [
    "Exercise 1.5\n",
    "------------\n",
    "Rerun the sinogram and listmode reconstruction (first cells of the notebook)\n",
    "using the 60min acquisition data by adapting the `acq_time` variable.\n",
    "Make sure that you restart the kernel before running the cells and to rerun\n",
    "the all cells (including scatter and random estimation).\n",
    "We wil use the 60min reconstruction in our last notebook."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
