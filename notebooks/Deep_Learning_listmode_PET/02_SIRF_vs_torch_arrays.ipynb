{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1f726e",
   "metadata": {},
   "source": [
    "SIRF.STIR ImageData objects vs numpy arrays vs torch tensors\n",
    "============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca5247",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Learning objectives of this notebook\n",
    "------------------------------------\n",
    "\n",
    "1. Understanding the differences between SIRF ImageData, numpy arrays and torch tensors.\n",
    "2. Learn how to convert between these different data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a8fc0",
   "metadata": {},
   "source": [
    "SIRF.STIR ImageData objects vs numpy arrays\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SIRF image template\n",
    "\n",
    "import sirf.STIR\n",
    "from sirf.Utilities import examples_data_path\n",
    "\n",
    "# read an example PET acquisition data set that we can use\n",
    "# to set up a compatible image data set\n",
    "acq_data: sirf.STIR.AcquisitionData = sirf.STIR.AcquisitionData(\n",
    "    examples_data_path(\"PET\") + \"/brain/template_sinogram.hs\"\n",
    ")\n",
    "\n",
    "# create a SIRF image compatible with the acquisition data\n",
    "# uses default voxel sizes and dimensions\n",
    "sirf_image_1: sirf.STIR.ImageData = acq_data.create_uniform_image(1.0)\n",
    "sirf_image_2: sirf.STIR.ImageData = acq_data.create_uniform_image(2.0)\n",
    "\n",
    "image_shape: tuple[int, int, int] = sirf_image_1.shape\n",
    "\n",
    "print()\n",
    "print(f\"sirf_image_1 shape   .: {sirf_image_1.shape}\")\n",
    "print(f\"sirf_image_1 spacing .: {sirf_image_1.spacing}\")\n",
    "print(f\"sirf_image_1 max     .: {sirf_image_1.max()}\")\n",
    "print()\n",
    "print(f\"sirf_image_2 shape   .: {sirf_image_2.shape}\")\n",
    "print(f\"sirf_image_2 spacing .: {sirf_image_2.spacing}\")\n",
    "print(f\"sirf_image_2 max     .: {sirf_image_2.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81cef5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# you retrieve the data behind a SIRF.STIR image as numpy array using the as_array() method\n",
    "import numpy as np\n",
    "\n",
    "numpy_image_1: np.ndarray = sirf_image_1.as_array()\n",
    "numpy_image_2: np.ndarray = sirf_image_2.as_array()\n",
    "\n",
    "numpy_image_2_modified = numpy_image_2.copy()\n",
    "numpy_image_2_modified[0, 0, 0] = 5.0\n",
    "numpy_image_2_modified[-1, -1, -1] = -4.0\n",
    "\n",
    "print()\n",
    "print(f\"numpy_image_1 shape   .: {numpy_image_1.shape}\")\n",
    "print(f\"numpy_image_1 max     .: {numpy_image_1.max()}\")\n",
    "print()\n",
    "print(f\"numpy_image_2 shape   .: {numpy_image_2.shape}\")\n",
    "print(f\"numpy_image_2 max     .: {numpy_image_2.max()}\")\n",
    "print()\n",
    "print(f\"numpy_image_2_modified shape .: {numpy_image_2_modified.shape}\")\n",
    "print(f\"numpy_image_2_modified max   .: {numpy_image_2_modified.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099104c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can convert a numpy array into a SIRF.STIR image using the fill() method\n",
    "\n",
    "# create a copy of sirf_image_2\n",
    "sirf_image_2_modified = sirf_image_2.get_uniform_copy()\n",
    "sirf_image_2_modified.fill(numpy_image_2_modified)\n",
    "\n",
    "print()\n",
    "print(f\"sirf_image_2 shape   .: {sirf_image_2.shape}\")\n",
    "print(f\"sirf_image_2 spacing .: {sirf_image_2.spacing}\")\n",
    "print(f\"sirf_image_2 max     .: {sirf_image_2.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8d734",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Exercise 2.1\n",
    "------------\n",
    "\n",
    "Create a SIRF.STIR image that is compatible with the acquisition data\n",
    "where every image \"plane\" contains the \"plane number squared\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the next line and run this cell\n",
    "%load snippets/solution_2_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4c5f4",
   "metadata": {},
   "source": [
    "torch tensors vs numpy arrays\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch tensors can live on different devices\n",
    "if torch.cuda.is_available():\n",
    "    # if cuda is availalbe, we want our torch tensor on the first CUDA device\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    # otherwise we select the CPU as device\n",
    "    dev = torch.device(\"cpu\")\n",
    "\n",
    "torch_image_1: torch.Tensor = torch.ones(image_shape, dtype=torch.float32, device=dev)\n",
    "\n",
    "print()\n",
    "print(f\"torch_image_1 shape  .: {torch_image_1.shape}\")\n",
    "print(f\"torch_image_1 max    .: {torch_image_1.max()}\")\n",
    "print(f\"torch_image_1 dtype  .: {torch_image_1.dtype}\")\n",
    "print(f\"torch_image_1 devive .: {torch_image_1.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can convert torch (GPU or CPU) tensors to numpy arrays using numpy() method\n",
    "numpy_image_from_torch_1: np.ndarray = torch_image_1.cpu().numpy()\n",
    "# see here: https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html\n",
    "\n",
    "# Attention: If the torch tensor lives on the CPU, the underlying array is not copied\n",
    "# and shared between the numpy and torch object!\n",
    "print()\n",
    "print(f\"numpy data pointer {numpy_image_from_torch_1.ctypes.data}\")\n",
    "print(f\"torch data pointer {torch_image_1.data_ptr()}\")\n",
    "\n",
    "if torch_image_1.data_ptr() == numpy_image_from_torch_1.ctypes.data:\n",
    "    print(\"numpy array and torch tensor share same data\")\n",
    "else:\n",
    "    print(\"numpy array and torch tensor don't share same data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbc8f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# You can create torch tensors from numpy array using torch.from_numpy()\n",
    "torch_image_from_numpy_1: torch.Tensor = torch.from_numpy(numpy_image_2)\n",
    "print()\n",
    "print(f\"torch_image_from_numpy_1 shape  .: {torch_image_from_numpy_1.shape}\")\n",
    "print(f\"torch_image_from_numpy_1 max    .: {torch_image_from_numpy_1.max()}\")\n",
    "\n",
    "# torch.from_numpy() will create a Tensor living on the CPU\n",
    "print()\n",
    "print(f\"device of torch tensor from numpy {torch_image_from_numpy_1.device}\")\n",
    "\n",
    "# we can send the tensor to our prefered device using the .to() method\n",
    "print(f\"sending tensor to device {dev.type}\")\n",
    "torch_image_from_numpy_1.to(dev)\n",
    "print(f\"device of torch tensor from numpy {torch_image_from_numpy_1.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46894319",
   "metadata": {},
   "source": [
    "Exercise 2.2\n",
    "------------\n",
    "\n",
    "Now that we know how to convert between SIRF.STIR images and numpy arrays,\n",
    "and between numpy arrays and torch tensors do the following:\n",
    "1. convert a torch tensor full of \"3s\" into SIRF.STIR ImageData object compatible\n",
    "   with the acquisition data\n",
    "2. convert a SIRF.STIR ImageData object \"sirf_image_1\" into a torch tensor on the\n",
    "   device \"dev\"\n",
    "3. Predict whether the different image objects should share data and test your\n",
    "   hypothesis\n",
    "4. Try to convert the torch tensor `torch.ones(image_shape, dtype=torch.float32, device=dev, requires_grad=True)`\n",
    "   into a numpy array. What do you observe?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
