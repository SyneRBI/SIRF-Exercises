{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f7a65a",
   "metadata": {},
   "source": [
    "Creating a custom unrolled variational network for listmode PET data\n",
    "====================================================================\n",
    "\n",
    "Learning objectives\n",
    "-------------------\n",
    "\n",
    "1. Learn how to implement and train a custom unrolled variational network fusing updates\n",
    "   from listmode OSEM blocks and CNN blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96928591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.STIR\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sirf.Utilities import examples_data_path\n",
    "\n",
    "# acq_time must be 1min\n",
    "acq_time: str = \"1min\"\n",
    "\n",
    "data_path: Path = Path(examples_data_path(\"PET\")) / \"mMR\"\n",
    "list_file: str = str(data_path / \"list.l.hdr\")\n",
    "norm_file: str = str(data_path / \"norm.n.hdr\")\n",
    "attn_file: str = str(data_path / \"mu_map.hv\")\n",
    "\n",
    "output_path: Path = data_path / f\"lm_recons_{acq_time}\"\n",
    "emission_sinogram_output_prefix: str = str(output_path / \"emission_sinogram\")\n",
    "scatter_sinogram_output_prefix: str = str(output_path / \"scatter_sinogram\")\n",
    "randoms_sinogram_output_prefix: str = str(output_path / \"randoms_sinogram\")\n",
    "attenuation_sinogram_output_prefix: str = str(output_path / \"acf_sinogram\")\n",
    "\n",
    "num_scatter_iter: int = 3\n",
    "\n",
    "lm_recon_output_file: str = str(output_path / \"lm_recon\")\n",
    "nxny: tuple[int, int] = (127, 127)\n",
    "num_subsets: int = 21\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "# engine's messages go to files, except error messages, which go to stdout\n",
    "_ = sirf.STIR.MessageRedirector(\"info.txt\", \"warn.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5111cf",
   "metadata": {},
   "source": [
    "Load listmode data and create the acquisition model\n",
    "---------------------------------------------------\n",
    "\n",
    "In this demo example, we use a simplified acquisition model that only implements the geometric forward projection.\n",
    "The effects of normalization, attenuation, scatter, randoms, are ignored but can be added as shown in the last\n",
    "example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64cb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sirf.STIR.AcquisitionData.set_storage_scheme(\"memory\")\n",
    "listmode_data = sirf.STIR.ListmodeData(list_file)\n",
    "acq_data_template = listmode_data.acquisition_data_template()\n",
    "\n",
    "acq_data = sirf.STIR.AcquisitionData(\n",
    "    str(Path(f\"{emission_sinogram_output_prefix}_f1g1d0b0.hs\"))\n",
    ")\n",
    "\n",
    "# select acquisition model that implements the geometric\n",
    "# forward projection by a ray tracing matrix multiplication\n",
    "acq_model = sirf.STIR.AcquisitionModelUsingRayTracingMatrix()\n",
    "acq_model.set_num_tangential_LORs(1)\n",
    "\n",
    "randoms = sirf.STIR.AcquisitionData(str(Path(f\"{randoms_sinogram_output_prefix}.hs\")))\n",
    "\n",
    "ac_factors = sirf.STIR.AcquisitionData(\n",
    "    str(Path(f\"{attenuation_sinogram_output_prefix}.hs\"))\n",
    ")\n",
    "asm_attn = sirf.STIR.AcquisitionSensitivityModel(ac_factors)\n",
    "\n",
    "asm_norm = sirf.STIR.AcquisitionSensitivityModel(norm_file)\n",
    "asm = sirf.STIR.AcquisitionSensitivityModel(asm_norm, asm_attn)\n",
    "\n",
    "asm.set_up(acq_data)\n",
    "acq_model.set_acquisition_sensitivity(asm)\n",
    "\n",
    "scatter_estimate = sirf.STIR.AcquisitionData(\n",
    "    str(Path(f\"{scatter_sinogram_output_prefix}_{num_scatter_iter}.hs\"))\n",
    ")\n",
    "acq_model.set_background_term(randoms + scatter_estimate)\n",
    "\n",
    "# setup an initial (template) image based on the acquisition data template\n",
    "initial_image = acq_data_template.create_uniform_image(value=1, xy=nxny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d84a5",
   "metadata": {},
   "source": [
    "Setup of the Poisson log likelihood listmode objective function\n",
    "---------------------------------------------------------------\n",
    "\n",
    "Using the listmode data and the acquisition model, we can now setup the Poisson log likelihood objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6d8e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "lm_obj_fun = (\n",
    "    sirf.STIR.PoissonLogLikelihoodWithLinearModelForMeanAndListModeDataWithProjMatrixByBin()\n",
    ")\n",
    "lm_obj_fun.set_acquisition_model(acq_model)\n",
    "lm_obj_fun.set_acquisition_data(listmode_data)\n",
    "lm_obj_fun.set_num_subsets(num_subsets)\n",
    "lm_obj_fun.set_cache_max_size(1000000000)\n",
    "lm_obj_fun.set_cache_path(str(output_path))\n",
    "print(\"setting up listmode objective function ...\")\n",
    "lm_obj_fun.set_up(initial_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9e7db",
   "metadata": {},
   "source": [
    "Setup of OSEM update layer\n",
    "--------------------------\n",
    "\n",
    "See notebook 04."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08da87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIRFPoissonlogLGradLayer(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        ctx,\n",
    "        x: torch.Tensor,\n",
    "        objective_function,\n",
    "        sirf_template_image: sirf.STIR.ImageData,\n",
    "        subset: int,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"(listmode) Poisson loglikelihood gradient layer forward pass\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ctx : context object\n",
    "            used to store objects that we need in the backward pass\n",
    "        x : torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the image\n",
    "        objective_function : sirf (listmode) objective function\n",
    "            the objective function that we use to calculate the gradient\n",
    "        sirf_template_image : sirf.STIR.ImageData\n",
    "            image template that we use to convert between torch tensors and sirf images\n",
    "        subset : int\n",
    "            subset number used for the gradient calculation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the image\n",
    "            containing the gradient of the (listmode) Poisson log likelihood at x\n",
    "        \"\"\"\n",
    "\n",
    "        # we use the context object ctx to store the matrix and other variables that we need in the backward pass\n",
    "        ctx.device = x.device\n",
    "        ctx.objective_function = objective_function\n",
    "        ctx.dtype = x.dtype\n",
    "        ctx.subset = subset\n",
    "        ctx.sirf_template_image = sirf_template_image\n",
    "\n",
    "        # setup a new sirf.STIR ImageData object\n",
    "        x_sirf = sirf_template_image.clone()\n",
    "        # convert torch tensor to sirf image via numpy\n",
    "        x_sirf.fill(x.cpu().numpy()[0, 0, ...])\n",
    "\n",
    "        # save the input sirf.STIR ImageData for the backward pass\n",
    "        ctx.x_sirf = x_sirf\n",
    "\n",
    "        # calculate the gradient of the Poisson log likelihood using SIRF\n",
    "        g_np = objective_function.gradient(x_sirf, subset).as_array()\n",
    "\n",
    "        # convert back to torch tensor\n",
    "        y = (\n",
    "            torch.tensor(g_np, device=ctx.device, dtype=ctx.dtype)\n",
    "            .unsqueeze(0)\n",
    "            .unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(\n",
    "        ctx, grad_output: torch.Tensor | None\n",
    "    ) -> tuple[torch.Tensor | None, None, None, None]:\n",
    "        \"\"\"(listmode) Poisson loglikelihood gradient layer backward pass\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ctx : context object\n",
    "            used to store objects that we need in the backward pass\n",
    "        grad_output : torch.Tensor | None\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the gradient (called v in the autograd tutorial)\n",
    "            https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#optional-reading-vector-calculus-using-autograd\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor | None, None, None, None]\n",
    "            the Jacobian-vector product of the Poisson log likelihood gradient layer\n",
    "        \"\"\"\n",
    "\n",
    "        if grad_output is None:\n",
    "            return None, None, None, None\n",
    "        else:\n",
    "            # convert torch tensor to sirf image via numpy\n",
    "            ctx.sirf_template_image.fill(grad_output.cpu().numpy()[0, 0, ...])\n",
    "\n",
    "            # calculate the Jacobian vector product (the Hessian applied to an image) using SIRF\n",
    "            back_sirf = ctx.objective_function.multiply_with_Hessian(\n",
    "                ctx.x_sirf, ctx.sirf_template_image, ctx.subset\n",
    "            )\n",
    "\n",
    "            # convert back to torch tensor via numpy\n",
    "            back = (\n",
    "                torch.tensor(back_sirf.as_array(), device=ctx.device, dtype=ctx.dtype)\n",
    "                .unsqueeze(0)\n",
    "                .unsqueeze(0)\n",
    "            )\n",
    "\n",
    "            return back, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSEMUpdateLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        objective_function,\n",
    "        sirf_template_image: sirf.STIR.ImageData,\n",
    "        subset: int,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        \"\"\"OSEM update layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        objective_function : sirf (listmode) objective function\n",
    "            the objective function that we use to calculate the gradient\n",
    "        sirf_template_image : sirf.STIR.ImageData\n",
    "            image template that we use to convert between torch tensors and sirf images\n",
    "        subset : int\n",
    "            subset number used for the gradient calculation\n",
    "        device : str\n",
    "            device used for the calculations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the OSEM\n",
    "            update of the input image using the Poisson log likelihood objective function\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._objective_function = objective_function\n",
    "        self._sirf_template_image: sirf.STIR.ImageData = sirf_template_image\n",
    "        self._subset: int = subset\n",
    "\n",
    "        self._poisson_logL_grad_layer = SIRFPoissonlogLGradLayer.apply\n",
    "\n",
    "        # setup a tensor containng the inverse of the subset sensitivity image adding the minibatch and channel dimensions\n",
    "        self._inv_sens_image: torch.Tensor = 1.0 / torch.tensor(\n",
    "            objective_function.get_subset_sensitivity(subset).as_array(),\n",
    "            dtype=torch.float32,\n",
    "            device=device,\n",
    "        ).unsqueeze(0).unsqueeze(0)\n",
    "        # replace positive infinity values with 0 (voxels with 0 sensitivity)\n",
    "        torch.nan_to_num(self._inv_sens_image, posinf=0, out=self._inv_sens_image)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward pass of the OSEM update layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            OSEM update image\n",
    "        \"\"\"\n",
    "        grad_x: torch.Tensor = self._poisson_logL_grad_layer(\n",
    "            x, self._objective_function, self._sirf_template_image, self._subset\n",
    "        )\n",
    "        return x + x * self._inv_sens_image * grad_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb68ff",
   "metadata": {},
   "source": [
    "Exercise 5.1\n",
    "------------\n",
    "\n",
    "Implement the forward pass of the unrolled OSEM Variational Network with 2 blocks shown below.\n",
    "Start from the code below and fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74a134",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class UnrolledOSEMVarNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        objective_function,\n",
    "        sirf_template_image: sirf.STIR.ImageData,\n",
    "        convnet: torch.nn.Module,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        \"\"\"Unrolled OSEM Variational Network with 2 blocks\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        objective_function : sirf.STIR objetive function\n",
    "            (listmode) Poisson logL objective function\n",
    "            that we use for the OSEM updates\n",
    "        sirf_template_image : sirf.STIR.ImageData\n",
    "            used for the conversion between torch tensors and sirf images\n",
    "        convnet : torch.nn.Module\n",
    "            a (convolutional) neural network that maps a minibatch tensor \n",
    "            of shape [1,1,spatial_dimensions] onto a minibatch tensor of the same shape\n",
    "        device : str\n",
    "            device used for the calculations\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # OSEM update layer using the 1st subset of the listmode data\n",
    "        self._osem_step_layer0 = OSEMUpdateLayer(\n",
    "            objective_function, sirf_template_image, 0, device\n",
    "        )\n",
    "\n",
    "        # OSEM update layer using the 2nd subset of the listmode data\n",
    "        self._osem_step_layer1 = OSEMUpdateLayer(\n",
    "            objective_function, sirf_template_image, 1, device\n",
    "        )\n",
    "        self._convnet = convnet\n",
    "        self._relu = torch.nn.ReLU()\n",
    "\n",
    "        # trainable parameters for the fusion of the OSEM update and the CNN output in the two blocks\n",
    "        self._fusion_weight0 = torch.nn.Parameter(\n",
    "            torch.ones(1, device=device, dtype=torch.float32)\n",
    "        )\n",
    "        self._fusion_weight1 = torch.nn.Parameter(\n",
    "            torch.ones(1, device=device, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward pass of the Unrolled OSEM Variational Network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            minibatch tensor of shape [1,1,spatial_dimensions] containing the output of the network\n",
    "        \"\"\"\n",
    "\n",
    "        # =============================================================\n",
    "        # =============================================================\n",
    "        # YOUR CODE HERE\n",
    "        #\n",
    "        # forward pass contains two blocks where each block\n",
    "        # consists of a fusion of the OSEM update and the CNN output\n",
    "        #\n",
    "        # the fusion is a weighted sum of the OSEM update and the CNN output\n",
    "        # using the respective fusion weights\n",
    "        #\n",
    "        # =============================================================\n",
    "        # ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37527103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view the solution, uncomment the line below and run the cell\n",
    "##%load snippets/solution_5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11747e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference OSEM reconstruction that we use a input our network\n",
    "lm_ref_recon = sirf.STIR.ImageData(f\"{lm_recon_output_file}.hv\")\n",
    "x_t = (\n",
    "    torch.tensor(\n",
    "        lm_ref_recon.as_array(), device=dev, dtype=torch.float32, requires_grad=False\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(0)\n",
    ")\n",
    "\n",
    "# define a minimal CNN that we use within the unrolled OSEM Variational Network\n",
    "cnn = torch.nn.Sequential(\n",
    "    torch.nn.Conv3d(1, 5, 5, padding=\"same\", bias=False),\n",
    "    torch.nn.Conv3d(5, 5, 5, padding=\"same\", bias=False),\n",
    "    torch.nn.PReLU(device=dev),\n",
    "    torch.nn.Conv3d(5, 5, 5, padding=\"same\", bias=False),\n",
    "    torch.nn.Conv3d(5, 5, 5, padding=\"same\", bias=False),\n",
    "    torch.nn.PReLU(device=dev),\n",
    "    torch.nn.Conv3d(5, 1, 1, padding=\"same\", bias=False),\n",
    ").to(dev)\n",
    "\n",
    "\n",
    "# setup the unrolled OSEM Variational Network using the sirf.STIR listmode objective function\n",
    "# and the CNN\n",
    "varnet = UnrolledOSEMVarNet(lm_obj_fun, initial_image, cnn, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df958b0f",
   "metadata": {},
   "source": [
    "\n",
    "Supervised optimization the network parameters\n",
    "----------------------------------------------\n",
    "\n",
    "The following cells demonstrate how to optimize the network parameters\n",
    "using a high quality target image (supervised learning).\n",
    "Here, we use the reconstruction of the 60min listmode data as the target image.\n",
    "\n",
    "**The purpose of the following cells is to demonstrate how the training of a network,\n",
    "works in principle. The aim is not to train a network that is actually useful!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 60min reference reconstruction\n",
    "# if you get an error loading this file, talk to your tutor\n",
    "lm_60min_ref_recon = sirf.STIR.ImageData(str(data_path / f\"lm_recons_60min\" / \"lm_recon.hv\"))\n",
    "\n",
    "# we have to scale the 60min reconstruction, since it is not reconcstructed in kBq/ml\n",
    "scale_factor = lm_ref_recon.as_array().mean() / lm_60min_ref_recon.as_array().mean()\n",
    "lm_60min_ref_recon *= scale_factor\n",
    "\n",
    "# define the high quality target image (mini-batch)\n",
    "target = (\n",
    "    torch.tensor(\n",
    "        lm_60min_ref_recon.as_array(),\n",
    "        device=dev,\n",
    "        dtype=torch.float32,\n",
    "        requires_grad=False,\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7b455",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# let's show the network input and the target image\n",
    "# remember that the network also takes listmode data, a listmode acq. model and the listmode objective function\n",
    "# as \"input\" (not shown here)\n",
    "\n",
    "vmax = float(target.max())\n",
    "sl = 71\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), tight_layout=True)\n",
    "ax[0].imshow(x_t.cpu().numpy()[0, 0, sl, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[1].imshow(target.cpu().numpy()[0, 0, sl, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax[0].set_title(\"network input (1min recon)\")\n",
    "ax[1].set_title(\"target (60min recon)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07118744",
   "metadata": {},
   "source": [
    "To train the network weights, we need to define an optimizer and a loss function.\n",
    "Here we use the Adam optimizer with a learning rate of 1e-3 and the Mean Squared Error (MSE) loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(varnet._convnet.parameters(), lr=1e-3)\n",
    "# define the loss function\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 10 updates of the model parameters using backpropagation of the\n",
    "# gradient of the loss function and the Adam optimizer\n",
    "\n",
    "num_epochs = 50\n",
    "training_loss = torch.zeros(num_epochs)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # pass the input mini-batch through the network\n",
    "    prediction = varnet(x_t)\n",
    "    # calculate the MSE loss between the prediction and the target\n",
    "    loss = loss_fct(prediction, target)\n",
    "    # backpropagate the gradient of the loss through the network\n",
    "    # (needed to update the trainable parameters of the network with an optimizer)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # update the trainable parameters of the network with the optimizer\n",
    "    optimizer.step()\n",
    "    print(i, loss.item())\n",
    "    # save the training loss\n",
    "    training_loss[i] = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "vmax = float(target.max())\n",
    "sl = 71\n",
    "\n",
    "fig1, ax1 = plt.subplots(2, 3, figsize=(9, 6), tight_layout=True)\n",
    "ax1[0, 0].imshow(x_t.cpu().numpy()[0, 0, sl, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax1[0, 1].imshow(\n",
    "    prediction.detach().cpu().numpy()[0, 0, sl, :, :], cmap=\"Greys\", vmin=0, vmax=vmax\n",
    ")\n",
    "ax1[0, 2].imshow(target.cpu().numpy()[0, 0, sl, :, :], cmap=\"Greys\", vmin=0, vmax=vmax)\n",
    "ax1[1, 0].imshow(\n",
    "    x_t.cpu().numpy()[0, 0, sl, :, :] - target.cpu().numpy()[0, 0, sl, :, :],\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-0.01,\n",
    "    vmax=0.01,\n",
    ")\n",
    "ax1[1, 1].imshow(\n",
    "    prediction.detach().cpu().numpy()[0, 0, sl, :, :]\n",
    "    - target.cpu().numpy()[0, 0, sl, :, :],\n",
    "    cmap=\"seismic\",\n",
    "    vmin=-0.01,\n",
    "    vmax=0.01,\n",
    ")\n",
    "\n",
    "ax1[0, 0].set_title(\"network input\")\n",
    "ax1[0, 1].set_title(\"network output\")\n",
    "ax1[0, 2].set_title(\"target\")\n",
    "ax1[1, 0].set_title(\"network input - target\")\n",
    "ax1[1, 1].set_title(\"network output - target\")\n",
    "fig1.show()\n",
    "\n",
    "# plot the training loss\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(training_loss.cpu().numpy())\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_ylabel(\"training loss\")\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
